import numpy as np
import mne
import pickle
import matplotlib.pyplot as plt
from nice.algorithms.connectivity import epochs_compute_wsmi
np.set_printoptions(threshold=100)  # Default threshold
mne.set_log_level('WARNING') 
import warnings
warnings.simplefilter("ignore", category=DeprecationWarning)
from scipy.stats import pearsonr
from scipy.stats import zscore
from scipy.signal import detrend
from numpy.polynomial.polynomial import Polynomial
from scipy.stats import ttest_rel

##---this calculates wsmi and pearson for LFP data

file_numbers = [1, 2, 4, 8, 14, 15, 20, 23]   #have dropped data 3


#for data set 3, error with left, but larger wsmi - seems indicative of a problem with the calculation
# file_numbers = [1]
# Initialize results dictionary for 10 datasets


def normalise_data(data):
    for i in range(len(data)):
        data[i] /= np.max(data[i])
    return data

classes_right = np.arange(0, 20)

for class_right in classes_right:
    results = {}
    for dataset in file_numbers:
        results[f'dataset_{dataset}'] = {
            'attention_left': {
                'larger wsmi': [],
                'larger pearson': []
            },
            'attention_right': {
                'larger wsmi': [],
                'larger pearson': []
            }
        }

    wsmi_means = {}
    wsmi_stdevs = {}
    n_values = {}
    
    for dataset in file_numbers:
        wsmi_means[f'dataset_{dataset}'] = {
            'left_attleft': [],
            'right_attleft': [],
            'left_attright': [],
            'right_attright': []
        }
        
        wsmi_stdevs[f'dataset_{dataset}'] = {
            'left_attleft': [],
            'right_attleft': [],
            'left_attright': [],
            'right_attright': []
        }
        
        n_values[f'dataset_{dataset}'] = {
            'attleft': [], 
            'attright': []
        }


    for file_number in file_numbers:
        # Load data
        file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'
        data = pickle.load(open(file_path, 'rb'))

        attention_labels = data['label_attend'][0]
        #print("attend", attention_labels[:10])
        label_left = data['label_left'][0]
        #print("label_left", label_left[:10])
        label_right = data['label_right'][0]
        #print("label_right", label_right[:10])
        attend_01 = data['attend'][0]
        #print ("attend01", attend_01[:10])


        #not filtered for omitted trials 
        left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right 
        right_input_LFP = data['LFP'][0][1]  # Right input
        attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention 
        omitted = data["omit"][0]


        left_indices = {}
        right_indices = {}

        for i in range(0, 20):
            left_indices[i] = np.where((omitted == 0) & (attend_01 == 0) & (label_left == i))[0]
            right_indices[i] = np.where((omitted == 0) & (attend_01 == 1) & (label_right == i))[0]



        #for left 0 and right ith
        left_input_LFP_om_left = left_input_LFP[left_indices[0]]
        left_input_LFP_om_left_relevant = left_input_LFP_om_left[:, 100:350]
        right_input_LFP_om_left = right_input_LFP[left_indices[0]]
        right_input_LFP_om_left_relevant = right_input_LFP_om_left[:, 100:350]
        attention_LFP_om_left = attention_LFP[left_indices[0]]
        attention_LFP_om_left_relevant = attention_LFP_om_left[:, 100:350]


        left_input_LFP_om_right = left_input_LFP[right_indices[class_right]]
        left_input_LFP_om_right_relevant = left_input_LFP_om_right[:, 100:350]
        right_input_LFP_om_right = right_input_LFP[right_indices[class_right]]
        right_input_LFP_om_right_relevant = right_input_LFP_om_right[:, 100:350]
        attention_LFP_om_right = attention_LFP[right_indices[class_right]]
        attention_LFP_om_right_relevant = attention_LFP_om_right[:, 100:350]

        
        n_values[f'dataset_{file_number}']['attleft'].append(len(left_input_LFP_om_left_relevant))
        n_values[f'dataset_{file_number}']['attright'].append(len(left_input_LFP_om_right_relevant))

        # fig, ax = plt.subplots(1, 2, figsize=(12, 6))

        # # Plot the first trial of the left input LFP om left relevant data (Attention Left)
        # ax[0].plot(np.mean(right_input_LFP_om_left_relevant, axis = 0), label='Right')
        # ax[0].plot(np.mean(left_input_LFP_om_left_relevant, axis=0), label='Left Mean')
        # ax[0].plot(np.mean(attention_LFP_om_left_relevant, axis=0), label='Attention Mean')
        # ax[0].set_xlabel('Time (ms)')
        # ax[0].set_ylabel('LFP')
        # ax[0].set_title('Mean Signal (Attention Left) before preprocessing')
        # ax[0].legend()

        # # Plot the mean signal of the left input LFP om right relevant data (Attention Right)
        # ax[1].plot(np.mean(left_input_LFP_om_right_relevant, axis=0), label='Left Mean')
        # ax[1].plot(np.mean(right_input_LFP_om_right_relevant, axis=0), label='Right Mean')
        # ax[1].plot(np.mean(attention_LFP_om_right_relevant, axis=0), label='Attention Mean')
        # ax[1].set_xlabel('Time (ms)')
        # ax[1].set_ylabel('LFP')
        # ax[1].set_title('Mean Signal (Attention Right) before preprocessing')
        # ax[1].legend()

        # plt.tight_layout()
        # plt.show()




        #---detrend across trials---
        left_input_LFP_om_left_relevant = detrend(left_input_LFP_om_left_relevant, axis=0)
        right_input_LFP_om_left_relevant = detrend(right_input_LFP_om_left_relevant, axis=0)
        attention_LFP_om_left_relevant = detrend(attention_LFP_om_left_relevant, axis=0)

        left_input_LFP_om_right_relevant = detrend(left_input_LFP_om_right_relevant, axis=0)
        right_input_LFP_om_right_relevant = detrend(right_input_LFP_om_right_relevant, axis=0)
        attention_LFP_om_right_relevant = detrend(attention_LFP_om_right_relevant, axis=0)


        #---detrend in time---
        for i in range(len(left_input_LFP_om_left_relevant)):
            left_input_LFP_om_left_relevant[i] = detrend(left_input_LFP_om_left_relevant[i])
            right_input_LFP_om_left_relevant[i] = detrend(right_input_LFP_om_left_relevant[i])
            attention_LFP_om_left_relevant[i] = detrend(attention_LFP_om_left_relevant[i])


        for i in range(len(left_input_LFP_om_right_relevant)):
            left_input_LFP_om_right_relevant[i] = detrend(left_input_LFP_om_right_relevant[i])
            right_input_LFP_om_right_relevant[i] = detrend(right_input_LFP_om_right_relevant[i])
            attention_LFP_om_right_relevant[i] = detrend(attention_LFP_om_right_relevant[i])


        
        ##---zscore across trials---
        left_input_LFP_om_left_relevant = zscore(left_input_LFP_om_left_relevant, axis=0)
        right_input_LFP_om_left_relevant = zscore(right_input_LFP_om_left_relevant, axis=0)
        attention_LFP_om_left_relevant = zscore(attention_LFP_om_left_relevant, axis=0)

        left_input_LFP_om_right_relevant = zscore(left_input_LFP_om_right_relevant, axis=0)
        right_input_LFP_om_right_relevant = zscore(right_input_LFP_om_right_relevant, axis=0)
        attention_LFP_om_right_relevant = zscore(attention_LFP_om_right_relevant, axis=0)


        

        # #can try smoothing here
        # from scipy.ndimage import gaussian_filter1d

        # def smooth_with_gaussian(data, sigma):
        #     return gaussian_filter1d(data, sigma=sigma, axis=1) 

        # sigma = 3 
        # attention_LFP_om_left_relevant = smooth_with_gaussian(attention_LFP_om_left_relevant, sigma=sigma) 
        # attention_LFP_om_right_relevant = smooth_with_gaussian(attention_LFP_om_right_relevant, sigma=sigma) 



        # fig, ax = plt.subplots(1, 2, figsize=(12, 6))

        # # Plot the mean signal of the left input LFP om left relevant data (Attention Left)
        # ax[0].plot(np.mean(left_input_LFP_om_left_relevant, axis=0), label='Left Input Mean')
        # ax[0].plot(np.mean(right_input_LFP_om_left_relevant, axis=0), label='Right Input Mean')
        # ax[0].plot(np.mean(attention_LFP_om_left_relevant, axis=0), label='Attention Mean')
        # ax[0].set_xlabel('Time (ms)')
        # ax[0].set_ylabel('LFP')
        # ax[0].set_title('Mean Signal (Attention Left) after preprocessing')
        # ax[0].legend()

        # # Plot the mean signal of the left input LFP om right relevant data (Attention Right)
        # ax[1].plot(np.mean(left_input_LFP_om_right_relevant, axis=0), label='Left Input Mean')
        # ax[1].plot(np.mean(right_input_LFP_om_right_relevant, axis=0), label='Right Input Mean')
        # ax[1].plot(np.mean(attention_LFP_om_right_relevant, axis=0), label='Attention Mean')
        # ax[1].set_xlabel('Time (ms)')
        # ax[1].set_ylabel('LFP')
        # ax[1].set_title('Mean Signal (Attention Right) after preprocessing')
        # ax[1].legend()

        # plt.tight_layout()
        # plt.show()


        n_times = left_input_LFP_om_left_relevant.shape[1] ##=250
        #print("n_samples", n_times)

        dt = 0.002
        sfreq = 1 / dt

        ch_names = ['left_input', 'right_input', 'attention_layer']
        ch_types = ['eeg', 'eeg', 'eeg']
        info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)


        #reshaping data for attention left
        raw_data_left = np.concatenate([
            left_input_LFP_om_left_relevant, 
            right_input_LFP_om_left_relevant, 
            attention_LFP_om_left_relevant 
        ], axis=0)  # Concatenate along time axis

        #print("raw_data_left shape =", raw_data_left.shape)  
        # Reshape into (n_channels, n_samples)
        raw_data_left = raw_data_left.reshape(3, -1)  
        #print('raw data left reshaped =', raw_data_left.shape) 
        raw_left = mne.io.RawArray(raw_data_left, info)
        #print("raw_data_left =", raw_left)
        

        #reshaping date for attention right 
        raw_data_right = np.concatenate([
            left_input_LFP_om_right_relevant,
            right_input_LFP_om_right_relevant,
            attention_LFP_om_right_relevant 
        ], axis=0)

        raw_data_right = raw_data_right.reshape(3, -1)
        raw_right = mne.io.RawArray(raw_data_right, info)


        #defininf event objects, arrays like [0,0,1], [500, 0, 1], [1000, 0, 1] etc
        events_left = np.array([[i * n_times, 0, 1] for i in range(len(left_input_LFP_om_left_relevant))])
        events_right = np.array([[i * n_times, 0, 1] for i in range(len(right_input_LFP_om_right_relevant))])

    
        epochs_left = mne.Epochs(raw_left, events_left, event_id={'Trial': 1}, tmin=0, tmax =  0.5,  baseline=None, preload=True)
        epochs_right = mne.Epochs(raw_right, events_right, event_id={'Trial': 1}, tmin=0, tmax = 0.5, baseline=None, preload=True)
    
        #print("epochs_left", epochs_left)
        # epochs_left.plot(n_epochs=5, n_channels=3, scalings = 'auto', title="Attention Left")
        # plt.show()

        kernel = 3
        taus = [8, 16, 32, 64]  # in ms
        wsmi_results = {'left': {}, 'right': {}}

        for tau in taus:
            tau_samples = int(tau / (1000 / sfreq))
                        
            wsmi_left, _, _, _ = epochs_compute_wsmi(
                epochs_left, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}
            )
            wsmi_results['left'][tau] = wsmi_left
            #this containts the data for wsmi at a given tau given attending left. 

            wsmi_right, _, _, _ = epochs_compute_wsmi(
                epochs_right, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}
            )
            wsmi_results['right'][tau] = wsmi_right

        wsmi_left_input_attleft = []  #wSMI for left input vs attention layer (attention left)
        wsmi_left_input_attleft_stdev = []  #wSMI for left input vs attention layer (attention left)
        wsmi_right_input_attleft = []  #wSMI for right input vs attention layer (attention left)
        wsmi_right_input_attleft_stdev = []  #wSMI for right input vs attention layer (attention left)
        wsmi_left_input_attright = []  #wSMI for left input vs attention layer (attention right)
        wsmi_left_input_attright_stdev = []  #wSMI for left input vs attention layer (attention right)
        wsmi_right_input_attright = []  #wSMI for right input vs attention layer (attention right)
        wsmi_right_input_attright_stdev = []  #wSMI for right input vs attention layer (attention right)

        #average wSMI for each τ for each condition
        for tau in taus:
            # For attention left
            wsmi_left_input_attleft.append(np.mean(wsmi_results['left'][tau][0, 2, :]))  # Left input vs attention layer
            wsmi_left_input_attleft_stdev.append(np.std(wsmi_results['left'][tau][0, 2, :], ddof = 1))  # Left input vs attention layer
            
            wsmi_right_input_attleft.append(np.mean(wsmi_results['left'][tau][1, 2, :]))  # Right input vs attention layer
            wsmi_right_input_attleft_stdev.append(np.std(wsmi_results['left'][tau][1, 2, :], ddof = 1))  # Right input vs attention layer

            # For attention right
            wsmi_left_input_attright.append(np.mean(wsmi_results['right'][tau][0, 2, :]))  # Left input vs attention layer
            wsmi_left_input_attright_stdev.append(np.std(wsmi_results['right'][tau][0, 2, :], ddof = 1))  # Left input vs attention layer

            wsmi_right_input_attright.append(np.mean(wsmi_results['right'][tau][1, 2, :]))  # Right input vs attention layer
            wsmi_right_input_attright_stdev.append(np.std(wsmi_results['right'][tau][1, 2, :], ddof = 1))  # Right input vs attention layer

        for tau in taus:
            if wsmi_left_input_attleft[taus.index(tau)] > wsmi_right_input_attleft[taus.index(tau)]:
                results[f'dataset_{file_number}']['attention_left']['larger wsmi'].append(0)
            else:
                results[f'dataset_{file_number}']['attention_left']['larger wsmi'].append(1)

            if wsmi_left_input_attright[taus.index(tau)] > wsmi_right_input_attright[taus.index(tau)]:
                results[f'dataset_{file_number}']['attention_right']['larger wsmi'].append(0)
            else:
                results[f'dataset_{file_number}']['attention_right']['larger wsmi'].append(1)

        for tau in taus:
            wsmi_means[f'dataset_{file_number}']['left_attleft'].append(np.mean(wsmi_results['left'][tau][0, 2, :]))
            wsmi_means[f'dataset_{file_number}']['right_attleft'].append(np.mean(wsmi_results['left'][tau][1, 2, :]))
            wsmi_means[f'dataset_{file_number}']['left_attright'].append(np.mean(wsmi_results['right'][tau][0, 2, :]))
            wsmi_means[f'dataset_{file_number}']['right_attright'].append(np.mean(wsmi_results['right'][tau][1, 2, :]))

            wsmi_stdevs[f'dataset_{file_number}']['left_attleft'].append(np.std(wsmi_results['left'][tau][0, 2, :], ddof = 1))
            wsmi_stdevs[f'dataset_{file_number}']['right_attleft'].append(np.std(wsmi_results['left'][tau][1, 2, :], ddof = 1))
            wsmi_stdevs[f'dataset_{file_number}']['left_attright'].append(np.std(wsmi_results['right'][tau][0, 2, :], ddof = 1))
            wsmi_stdevs[f'dataset_{file_number}']['right_attright'].append(np.std(wsmi_results['right'][tau][1, 2, :], ddof = 1))


        # fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

        # #left subplot
        # axs[0].errorbar(taus, wsmi_left_input_attleft, yerr=wsmi_left_input_attleft_stdev, fmt='x', color='r', label="Left Input vs Attention Layer", capsize=5)
        # axs[0].errorbar(taus, wsmi_right_input_attleft, yerr=wsmi_right_input_attleft_stdev, fmt='x', color='k', label="Right Input vs Attention Layer", capsize=5)
        # axs[0].set_title("Attention Left", fontsize=14)
        # axs[0].set_xlabel("τ (ms)", fontsize=12)
        # axs[0].set_ylabel("Average wSMI", fontsize=12)
        # axs[0].legend()
        # axs[0].grid(False)

        # #right subplot
        # axs[1].errorbar(taus, wsmi_left_input_attright, yerr=wsmi_left_input_attright_stdev, fmt='x', color='r', label="Left Input vs Attention Layer", capsize=5)
        # axs[1].errorbar(taus, wsmi_right_input_attright, yerr=wsmi_right_input_attright_stdev, fmt='x', color='k', label="Right Input vs Attention Layer", capsize=5)
        # axs[1].set_title("Attention Right", fontsize=14)
        # axs[1].set_xlabel("τ (ms)", fontsize=12)
        # axs[1].legend()
        # axs[1].grid(False)

        # plt.tight_layout()
        # plt.show()


        # print('wsmi_results.shape', wsmi_results['left'][8].shape)
        # #wsmi_results.shape (3, 3, 468), so get a 3x3 for each trial. note that values for performing a single trial are different to 
        # #extracting the wsmi value of the first trial from wsmi_results. unsure why. 

        # for tau_to_check in taus:
        #     wsmi_first_trial_left = wsmi_results['left'][tau_to_check][:, :, 0] 
        #     print(f"wSMI matrix for the first trial (attention left) at tau={tau_to_check} ms:\n", wsmi_first_trial_left)


        attleft_pearson_left = []
        attleft_pearson_right = []
        attright_pearson_left = []
        attright_pearson_right = []

        for i in range(len(left_input_LFP_om_left_relevant)):
            corr_left, _ = pearsonr(left_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])
            attleft_pearson_left.append(corr_left)
            corr_right, _ = pearsonr(right_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])
            attleft_pearson_right.append(corr_right)

        for i in range(len(left_input_LFP_om_right_relevant)):
            corr_left, _ = pearsonr(left_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])
            attright_pearson_left.append(corr_left)
            corr_right, _ = pearsonr(right_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])
            attright_pearson_right.append(corr_right)

        mean_corr_left_attleft = np.mean(attleft_pearson_left)
        mean_corr_right_attleft = np.mean(attleft_pearson_right)
        mean_corr_left_attright = np.mean(attright_pearson_left)
        mean_corr_right_attright = np.mean(attright_pearson_right)


        if mean_corr_left_attleft > mean_corr_right_attleft:
            results[f'dataset_{file_number}']['attention_left']['larger pearson'].append(0)
        else:
            results[f'dataset_{file_number}']['attention_left']['larger pearson'].append(1)

        if mean_corr_left_attright > mean_corr_right_attright:
            results[f'dataset_{file_number}']['attention_right']['larger pearson'].append(0)
        else:
            results[f'dataset_{file_number}']['attention_right']['larger pearson'].append(1)

        
        # x = [0, 1]
        # fig, axs = plt.subplots(1, 2, figsize=(12, 6))
        # axs[0].scatter(x, [mean_corr_left_attleft, mean_corr_right_attleft],
        #             label="Attention Left", color='k', marker='x', s=100)
        # axs[1].scatter(x, [mean_corr_left_attright, mean_corr_right_attright],
        #             label="Attention Right", color='k', marker='x', s=100)

        # for ax in axs:
        #     ax.set_xticks(x)
        #     ax.set_xticklabels(['left', 'right'])
        #     ax.set_xlim(-0.7, 1.7)

        # axs[0].set_title("Attention Left", fontsize=14)
        # axs[1].set_title("Attention Right", fontsize=14)
        # axs[0].set_ylabel("Mean Pearson Correlation", fontsize=12)
        # axs[1].set_ylabel("Mean Pearson Correlation", fontsize=12)

        # axs[0].grid(False)
        # axs[1].grid(False)

        # plt.tight_layout()
        # plt.show()


    #----------------------------plotting and calculating mean and stdev for wsmi and pearson---------------------------
        
    print(results)

    mean_wsmi_left_attleft = []
    mean_wsmi_right_attleft = []
    mean_wsmi_left_attright = []
    mean_wsmi_right_attright = []

    stdev_wsmi_left_attleft = []
    stdev_wsmi_right_attleft = []
    stdev_wsmi_left_attright = []
    stdev_wsmi_right_attright = []


    cmll = []
    cmlr = []
    cmrl = []
    cmrr = []


    print("shape of n_values;", np.array(n_values).shape)
    print("n_values", n_values)
    #n_values
    # {'dataset_1': {'attleft': [468], 'attright': [536]}, 
    # 'dataset_2': {'attleft': [463], 'attright': [479]}, 
    # 'dataset_4': {'attleft': [471], 'attright': [455]}}

    n_left = np.sum([np.array(n_values[f'dataset_{dataset}']['attleft'][0]) for dataset in file_numbers])
    n_right = np.sum([np.array(n_values[f'dataset_{dataset}']['attright'][0]) for dataset in file_numbers])
   
    n_left_minus = np.sum([(n_values[f'dataset_{dataset}']['attleft'][0] - 1) for dataset in file_numbers])
    n_right_minus = np.sum([(n_values[f'dataset_{dataset}']['attright'][0] - 1) for dataset in file_numbers])
   

    taus = [0, 1, 2, 3]
    for tau_idx in taus:
        #first calculate the dataset means:
        #this takes the mean of the wsmi_means in each dataset for each tau and condition. 
        mean_wsmi_left_attleft.append(np.mean([(wsmi_means[f'dataset_{dataset}']['left_attleft'][tau_idx]) for dataset in file_numbers]))
        mean_wsmi_right_attleft.append(np.mean([(wsmi_means[f'dataset_{dataset}']['right_attleft'][tau_idx]) for dataset in file_numbers]))
        mean_wsmi_left_attright.append(np.mean([(wsmi_means[f'dataset_{dataset}']['left_attright'][tau_idx]) for dataset in file_numbers]))
        mean_wsmi_right_attright.append(np.mean([(wsmi_means[f'dataset_{dataset}']['right_attright'][tau_idx]) for dataset in file_numbers]))

        cmll.append((np.sum([n_values[f'dataset_{dataset}']['attleft'][0] * (wsmi_means[f'dataset_{dataset}']['left_attleft'][tau_idx]) for dataset in file_numbers])) / (n_left))
        cmlr.append((np.sum([n_values[f'dataset_{dataset}']['attleft'][0] * (wsmi_means[f'dataset_{dataset}']['right_attleft'][tau_idx]) for dataset in file_numbers])) / (n_left))
        cmrl.append((np.sum([n_values[f'dataset_{dataset}']['attright'][0] * (wsmi_means[f'dataset_{dataset}']['left_attright'][tau_idx]) for dataset in file_numbers])) / (n_right))
        cmrr.append((np.sum([n_values[f'dataset_{dataset}']['attright'][0] * (wsmi_means[f'dataset_{dataset}']['right_attright'][tau_idx]) for dataset in file_numbers])) / (n_right))


        
        stdev_wsmi_left_attleft.append(np.sqrt(((np.sum([(n_values[f'dataset_{dataset}']['attleft'][0] - 1) * \
                                                        (((wsmi_stdevs[f'dataset_{dataset}']['left_attleft'][tau_idx]))**2) for dataset in file_numbers])) + \
                                                            np.sum([((n_values[f'dataset_{dataset}']['attleft'][0]) * (cmll[tau_idx] - (wsmi_means[f'dataset_{dataset}']['left_attleft'][tau_idx]))**2 ) for dataset in file_numbers])) \
                                                                / (n_left - 1) ))

        stdev_wsmi_right_attleft.append(np.sqrt(((np.sum([(n_values[f'dataset_{dataset}']['attleft'][0] - 1) * \
                                                        (((wsmi_stdevs[f'dataset_{dataset}']['right_attleft'][tau_idx]))**2) for dataset in file_numbers])) + \
                                                            np.sum([ ((n_values[f'dataset_{dataset}']['attleft'][0]) * (cmrl[tau_idx] - (wsmi_means[f'dataset_{dataset}']['right_attleft'][tau_idx]))**2 ) for dataset in file_numbers])) \
                                                                / (n_left - 1) ))

        stdev_wsmi_left_attright.append(np.sqrt(((np.sum([(n_values[f'dataset_{dataset}']['attright'][0] - 1) * \
                                                        (((wsmi_stdevs[f'dataset_{dataset}']['left_attright'][tau_idx]))**2) for dataset in file_numbers])) + \
                                                            np.sum([ ((n_values[f'dataset_{dataset}']['attright'][0]) * (cmlr[tau_idx] - (wsmi_means[f'dataset_{dataset}']['left_attright'][tau_idx]))**2 ) for dataset in file_numbers])) \
                                                                / (n_right -1) ))

        stdev_wsmi_right_attright.append(np.sqrt(((np.sum([(n_values[f'dataset_{dataset}']['attright'][0] - 1) * \
                                                        (((wsmi_stdevs[f'dataset_{dataset}']['left_attright'][tau_idx]))**2) for dataset in file_numbers])) + \
                                                            np.sum([ ((n_values[f'dataset_{dataset}']['attright'][0]) * (cmrr[tau_idx] - (wsmi_means[f'dataset_{dataset}']['left_attright'][tau_idx]))**2 ) for dataset in file_numbers])) \
                                                                / (n_right - 1) ))


        #---------have used the above to calculate stdev rather than below, as it accounts correctly for datasets of different sizes, relevant here when checking specific classes where no. cases is variable 
        # stdev_wsmi_left_attleft.append(np.sqrt((np.sum([(n_values[f'dataset_{dataset}']['attleft'][0] - 1) * (((wsmi_stdevs[f'dataset_{dataset}']['left_attleft'][tau_idx]))**2 + (cmlr[tau_idx] - (wsmi_means[f'dataset_{dataset}']['left_attleft'][tau_idx]))**2) for dataset in file_numbers])) / n_left_minus ))
        # stdev_wsmi_right_attleft.append(np.sqrt((np.sum([(n_values[f'dataset_{dataset}']['attleft'][0] - 1) * (((wsmi_stdevs[f'dataset_{dataset}']['right_attleft'][tau_idx]))**2 + (cmlr[tau_idx] - (wsmi_means[f'dataset_{dataset}']['right_attleft'][tau_idx]))**2) for dataset in file_numbers])) / n_left_minus ))
        # stdev_wsmi_left_attright.append(np.sqrt((np.sum([(n_values[f'dataset_{dataset}']['attright'][0] - 1) * (((wsmi_stdevs[f'dataset_{dataset}']['left_attright'][tau_idx]))**2 + (cmrl[tau_idx] - (wsmi_means[f'dataset_{dataset}']['left_attright'][tau_idx]))**2) for dataset in file_numbers])) / n_right_minus ))
        # stdev_wsmi_right_attright.append(np.sqrt((np.sum([(n_values[f'dataset_{dataset}']['attright'][0] - 1) * (((wsmi_stdevs[f'dataset_{dataset}']['right_attright'][tau_idx]))**2 + (cmrr[tau_idx] - (wsmi_means[f'dataset_{dataset}']['right_attright'][tau_idx]))**2) for dataset in file_numbers])) / n_right_minus ))

    #cmll looks at a particular tau, e.g. tau is 4 - begins in dataset 1, takes number of trials for attention left and multiplies
        #by the mean for dataset 1, left left, tau = 4. it does the same for all datasets and divides by the total number of trials over dataset (for given tau)       
    #stdev is calculated using correct conbined standard deviaiton formula, which weights deviations from combined mean by number of trials in each dataset

    #--calculating standard error in the mean--
    SEM_ll = stdev_wsmi_left_attleft / np.sqrt(n_left)
    SEM_lr = stdev_wsmi_right_attleft / np.sqrt(n_left)
    SEM_rl = stdev_wsmi_left_attright / np.sqrt(n_right)
    SEM_rr = stdev_wsmi_right_attright / np.sqrt(n_right)


    taus = [ 8, 16, 32, 64]                                 
    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

    #left subplot
    axs[0].errorbar(taus, mean_wsmi_left_attleft, yerr=SEM_ll, fmt='x', color='r', label="Left Input vs Attention Layer", capsize=5)
    axs[0].errorbar(taus, mean_wsmi_right_attleft, yerr=SEM_rl, fmt='x', color='k', label="Right Input vs Attention Layer", capsize=5)
    axs[0].set_title(f"wSMI - Attention Left - LFP - right class = {class_right}", fontsize=14)
    axs[0].set_xlabel("τ (ms)", fontsize=12)
    axs[0].set_ylabel("Average wSMI", fontsize=12)
    axs[0].legend()
    axs[0].grid(False)

    #right subplot
    axs[1].errorbar(taus, mean_wsmi_left_attright, yerr=SEM_lr, fmt='x', color='r', label="Left Input vs Attention Layer", capsize=5)
    axs[1].errorbar(taus, mean_wsmi_right_attright, yerr=SEM_rr, fmt='x', color='k', label="Right Input vs Attention Layer", capsize=5)
    axs[1].set_title(f"wSMI - Attention Right - LFP - right class = {class_right}", fontsize=14)
    axs[1].set_xlabel("τ (ms)", fontsize=12)
    axs[1].legend()
    axs[1].grid(False)

    plt.tight_layout()
    
    #saving the figure
    import os
    output_dir = r'C:\Users\joshu\OneDrive\Documents\Physics\PartIII\Project\180225_different_class_plots'
    os.makedirs(output_dir, exist_ok=True)
    fig.savefig(f'{output_dir}/LFP_0{class_right}.png')
    

    ##----------- t-test for each value tau -------------------

    print('t-test for each value tau across datasets')
    tau_idx = [0, 1, 2, 3]
    tau_values = [8, 16, 32, 64]
    for tau in tau_idx:
        t_stat, p_value = ttest_rel([wsmi_means[f'dataset_{dataset}']['left_attleft'][tau] for dataset in file_numbers], \
            [wsmi_means[f'dataset_{dataset}']['right_attleft'][tau] for dataset in file_numbers])
        print(f"---left, tau = {tau_values[tau]}")
        print(f"t_statistic: {t_stat}")
        print(f"p_value: {p_value}")

        t_stat, p_value = ttest_rel([wsmi_means[f'dataset_{dataset}']['left_attright'][tau] for dataset in file_numbers], \
            [wsmi_means[f'dataset_{dataset}']['right_attright'][tau] for dataset in file_numbers])
        print(f"---right, tau = {tau_values[tau]}")
        print(f"t_statistic: {t_stat}")
        print(f"p_value: {p_value}")



    #save print log to a text file
    output_log_path = os.path.join(output_dir, f'LFP_0{class_right}_ttest_results.txt')
    with open(output_log_path, 'w') as f:
        f.write('t-test for each value tau across datasets\n')
        for tau in tau_idx:
            t_stat, p_value = ttest_rel([wsmi_means[f'dataset_{dataset}']['left_attleft'][tau] for dataset in file_numbers], 
                                        [wsmi_means[f'dataset_{dataset}']['right_attleft'][tau] for dataset in file_numbers])
            f.write(f"---left, tau = {tau_values[tau]}\n")
            f.write(f"t_statistic: {t_stat}\n")
            f.write(f"p_value: {p_value}\n")

            t_stat, p_value = ttest_rel([wsmi_means[f'dataset_{dataset}']['left_attright'][tau] for dataset in file_numbers], 
                                        [wsmi_means[f'dataset_{dataset}']['right_attright'][tau] for dataset in file_numbers])
            f.write(f"---right, tau = {tau_values[tau]}\n")
            f.write(f"t_statistic: {t_stat}\n")
            f.write(f"p_value: {p_value}\n")



    # #--------t-test on averages ----------------

    # print('----- averaged across datasets -----')
    # mean_wsmi_left_attleft = np.array(mean_wsmi_left_attleft)
    # mean_wsmi_right_attleft = np.array(mean_wsmi_right_attleft)
    # mean_wsmi_left_attright = np.array(mean_wsmi_left_attright)
    # mean_wsmi_right_attright = np.array(mean_wsmi_right_attright)


    # t_stat, p_value = ttest_rel(mean_wsmi_left_attleft, mean_wsmi_right_attleft)
    # print('--left--')
    # print(f"t-statistic: {t_stat}")
    # print(f"p-value: {p_value}")

    # t_stat, p_value = ttest_rel(mean_wsmi_left_attright, mean_wsmi_right_attright)
    # print('--right--')
    # print(f"t-statistic: {t_stat}")
    # print(f"p-value: {p_value}")


    # #---------dont want to do this ^^^^, want to do t-test for each session (dependent) -----------------


    # print('----- for each dataset -----')

    # for dataset in file_numbers:
    #     t_stat, p_value = ttest_rel(wsmi_means[f'dataset_{dataset}']['left_attleft'], wsmi_means[f'dataset_{dataset}']['right_attleft'])
    #     print('--left--')
    #     print(f"t-statistic: {t_stat}")
    #     print(f"p-value: {p_value}")

    #     t_stat, p_value = ttest_rel(wsmi_means[f'dataset_{dataset}']['left_attright'], wsmi_means[f'dataset_{dataset}']['right_attright'])
    #     print('--right--')
    #     print(f"t-statistic: {t_stat}")
    #     print(f"p-value: {p_value}")

    # print('\\\\')
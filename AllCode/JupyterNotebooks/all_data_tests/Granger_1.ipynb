{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2bd58-1b78-4554-9a46-be2828a22d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\externals\\tempita\\__init__.py:35: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mne_connectivity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmne\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmne_connectivity\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mne_connectivity'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import detrend\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "\n",
    "#---this calculates the granger causality for the LFP data---\n",
    "\n",
    "i_values = [1, 2, 4, 8, 14, 15, 20, 23]\n",
    "    # Normalize the data (Z-score and Detrend)\n",
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = detrend(zscore(data[i]))\n",
    "        data[i] /= np.max(np.abs(data[i]))  # Normalize\n",
    "    return data\n",
    "\n",
    "\n",
    "for file_number in i_values:\n",
    "    # Load data\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    # Extract relevant data\n",
    "    left_input_LFP = data['LFP'][0][0] \n",
    "    right_input_LFP = data['LFP'][0][1] \n",
    "    attention_LFP = data['LFP_rec'][0][2]  \n",
    "    omitted = data[\"omit\"][0]\n",
    "\n",
    "    label_left = data['label_left'][0]\n",
    "    label_right = data['label_right'][0]\n",
    "    attend_01 = data['attend'][0]\n",
    "\n",
    "    # Get valid trial indices\n",
    "    left_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 0))[0]\n",
    "    right_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 1))[0]\n",
    "\n",
    "    # Slice the data\n",
    "    left_input_LFP_om_left_relevant = left_input_LFP[left_indices, 100:350]\n",
    "    right_input_LFP_om_left_relevant = right_input_LFP[left_indices, 100:350]\n",
    "    attention_LFP_om_left_relevant = attention_LFP[left_indices, 100:350]\n",
    "\n",
    "    left_input_LFP_om_right_relevant = left_input_LFP[right_indices, 100:350]\n",
    "    right_input_LFP_om_right_relevant = right_input_LFP[right_indices, 100:350]\n",
    "    attention_LFP_om_right_relevant = attention_LFP[right_indices, 100:350]\n",
    "\n",
    "\n",
    "    left_input_LFP_om_left_relevant = preprocess_data(left_input_LFP_om_left_relevant)\n",
    "    right_input_LFP_om_left_relevant = preprocess_data(right_input_LFP_om_left_relevant)\n",
    "    attention_LFP_om_left_relevant = preprocess_data(attention_LFP_om_left_relevant)\n",
    "\n",
    "    left_input_LFP_om_right_relevant = preprocess_data(left_input_LFP_om_right_relevant)\n",
    "    right_input_LFP_om_right_relevant = preprocess_data(right_input_LFP_om_right_relevant)\n",
    "    attention_LFP_om_right_relevant = preprocess_data(attention_LFP_om_right_relevant)\n",
    "\n",
    "    # Stack data into shape (n_trials, n_channels, n_samples)\n",
    "    data_left = np.stack([left_input_LFP_om_left_relevant, right_input_LFP_om_left_relevant, attention_LFP_om_left_relevant], axis=1)\n",
    "    data_right = np.stack([left_input_LFP_om_right_relevant, right_input_LFP_om_right_relevant, attention_LFP_om_right_relevant], axis=1)\n",
    "\n",
    "    # Define MNE info\n",
    "    sfreq = 500  # Sampling frequency\n",
    "    ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "    ch_types = ['eeg', 'eeg', 'eeg']\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    # Create events array\n",
    "    n_times = data_left.shape[2]  # Number of samples per trial\n",
    "    events_left = np.array([[i * n_times, 0, 1] for i in range(data_left.shape[0])])\n",
    "    events_right = np.array([[i * n_times, 0, 1] for i in range(data_right.shape[0])])\n",
    "\n",
    "    # Convert data into MNE Epochs\n",
    "    epochs_left = mne.EpochsArray(data_left, info, events=events_left, tmin=0)\n",
    "    epochs_right = mne.EpochsArray(data_right, info, events=events_right, tmin=0)\n",
    "\n",
    "    # Define channel indices for Granger causality\n",
    "    seeds = np.array([[0], [1]])\n",
    "    targets = np.array([[2], [2]])\n",
    "    indices = (seeds, targets)\n",
    "\n",
    "    # Compute Granger causality\n",
    "    gc_left = spectral_connectivity_epochs(\n",
    "        epochs_left, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    gc_right = spectral_connectivity_epochs(\n",
    "        epochs_right, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    # Extract Granger causality data\n",
    "    gc_data_left = gc_left.get_data()\n",
    "    gc_data_right = gc_right.get_data()\n",
    "    freqs = gc_left.freqs\n",
    "\n",
    "    # Plot Granger causality results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].plot(freqs, gc_data_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[0].plot(freqs, gc_data_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[0].set_title(\"Attention Left - Dataset \" + str(file_number))\n",
    "    ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[0].set_ylabel(\"Granger Causality\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(freqs, gc_data_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[1].plot(freqs, gc_data_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[1].set_title(\"Attention Right - Dataset \" + str(file_number))\n",
    "    ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[1].set_ylabel(\"Granger Causality\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Define channel indices for Granger causality\n",
    "    targets = np.array([[0], [1]])\n",
    "    seeds = np.array([[2], [2]])\n",
    "    indices = (seeds, targets)\n",
    "\n",
    "    # Compute Granger causality\n",
    "    gc_left_back = spectral_connectivity_epochs(\n",
    "        epochs_left, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    gc_right_back = spectral_connectivity_epochs(\n",
    "        epochs_right, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    # Extract Granger causality data\n",
    "    gc_data_left_back = gc_left_back.get_data()\n",
    "    gc_data_right_back = gc_right_back.get_data()\n",
    "    freqs = gc_left.freqs\n",
    "\n",
    "    net_gc_left = gc_data_left - gc_data_left_back\n",
    "    net_gc_right = gc_data_right - gc_data_right_back\n",
    "\n",
    "    # Plot Granger causality results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].plot(freqs, net_gc_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[0].plot(freqs, net_gc_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[0].set_title(\"Attention Left - Dataset \" + str(file_number))\n",
    "    ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[0].set_ylabel(\"Granger Causality\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(freqs, net_gc_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[1].plot(freqs, net_gc_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[1].set_title(\"Attention Right - Dataset \" + str(file_number))\n",
    "    ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[1].set_ylabel(\"Granger Causality\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #time reversed\n",
    "    # Define channel indices for Granger causality\n",
    "    seeds = np.array([[0], [1]])\n",
    "    targets = np.array([[2], [2]])\n",
    "    indices = (seeds, targets)\n",
    "\n",
    "    # Compute Granger causality\n",
    "    gc_left = spectral_connectivity_epochs(\n",
    "        epochs_left, method='gc_tr', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    gc_right = spectral_connectivity_epochs(\n",
    "        epochs_right, method='gc_tr', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=40.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    # Extract Granger causality data\n",
    "    gc_data_left = gc_left.get_data()\n",
    "    gc_data_right = gc_right.get_data()\n",
    "    freqs = gc_left.freqs\n",
    "\n",
    "    # Plot Granger causality results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].plot(freqs, gc_data_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[0].plot(freqs, gc_data_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[0].set_title(\"Attention Left - Dataset \" + str(file_number))\n",
    "    ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[0].set_ylabel(\"Granger Causality\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(freqs, gc_data_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[1].plot(freqs, gc_data_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[1].set_title(\"Attention Right - Dataset \" + str(file_number))\n",
    "    ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[1].set_ylabel(\"Granger Causality\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e33e8e-b8f7-4c41-b9f7-3469adb22e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import detrend\n",
    "np.set_printoptions(threshold=100)  # Default threshold\n",
    "mne.set_log_level('WARNING')  # This will hide INFO messages\n",
    "\n",
    "#this calculates the granger causality for the spiking data---\n",
    "\n",
    "\n",
    "i_values = [1, 2, 3, 4, 8, 14, 15, 20, 23]\n",
    "\n",
    "results = {}\n",
    "for store in i_values:\n",
    "    results[f'dataset_{store}'] = {\n",
    "        'attention_left': {\n",
    "            'larger wsmi': [],\n",
    "            'larger pearson': [],\n",
    "      \n",
    "        },\n",
    "        'attention_right': {\n",
    "            'larger wsmi': [],\n",
    "            'larger pearson': [],\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "for file_number in i_values:\n",
    "    # Load data\n",
    "\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    left_input_SP = data['SP'][0][0] \n",
    "    right_input_SP = data['SP'][0][1]\n",
    "    attention_SP = data['SP'][0][2]\n",
    "    label_left = data['label_left'][0]\n",
    "    label_right = data['label_right'][0]\n",
    "    # left_input_SP (2032, 500, 160)\n",
    "    # right_input_SP (2032, 500, 160)\n",
    "    # attention_SP (2032, 500, 80)\n",
    "    \n",
    "\n",
    "    # attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "    # attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "\n",
    "    attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0))[0]\n",
    "    attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0))[0]\n",
    "\n",
    "    left_input_attendingleft_t = left_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    right_input_attendingleft_t = right_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingleft_t = attention_SP[attend_left_not_omitted, 100:350, :]\n",
    "\n",
    "    left_input_attendingright_t = left_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    right_input_attendingright_t = right_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingright_t = attention_SP[attend_right_not_omitted, 100:350, :]\n",
    "\n",
    "    #eft_input_attendingleft_t (468, 250, 160) (80 for attention)\n",
    "    #left_input_attendingright_t (536, 250, 160) (80 for attention)\n",
    "\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "    def smooth_with_gaussian(data, sigma=3):\n",
    "        return gaussian_filter1d(data, sigma=sigma, axis=1) \n",
    "\n",
    "    sigma = 2\n",
    "\n",
    "    left_in_attleft_sm = smooth_with_gaussian(left_input_attendingleft_t, sigma=sigma) \n",
    "    right_in_attleft_sm = smooth_with_gaussian(right_input_attendingleft_t, sigma=sigma) \n",
    "    attlay_attleft_sm = smooth_with_gaussian(attention_layer_attendingleft_t, sigma=sigma) \n",
    "\n",
    "    left_in_attright_sm = smooth_with_gaussian(left_input_attendingright_t, sigma=sigma) \n",
    "    right_in_attright_sm = smooth_with_gaussian(right_input_attendingright_t, sigma=sigma)\n",
    "    attlay_attright_sm = smooth_with_gaussian(attention_layer_attendingright_t, sigma=sigma)\n",
    "\n",
    "\n",
    "    num_trials_left, num_samples, num_neurons_left = left_input_attendingleft_t.shape\n",
    "    num_trials_right = left_input_attendingright_t.shape[0]\n",
    "    num_neurons_attention = 80\n",
    "\n",
    "            \n",
    "    for j in range(0, num_trials_left):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attleft_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attleft_sm[j, :, i] /= count_right\n",
    "\n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingleft_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attleft_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(0, num_trials_right):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attright_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attright_sm[j, :, i] /= count_right    \n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingright_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attright_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    left_in_attleft_sum = np.sum(left_in_attleft_sm, axis=2)\n",
    "    right_in_attleft_sum = np.sum(right_in_attleft_sm, axis=2)\n",
    "    attlay_attleft_sum = np.sum(attlay_attleft_sm, axis=2)\n",
    "\n",
    "    left_in_attright_sum = np.sum(left_in_attright_sm, axis=2)\n",
    "    right_in_attright_sum = np.sum(right_in_attright_sm, axis=2)\n",
    "    attlay_attright_sum = np.sum(attlay_attright_sm, axis=2)\n",
    "\n",
    "   \n",
    "\n",
    "    # Check for NaN or Inf values in the summed data\n",
    "    def check_nan_inf(data, label):\n",
    "        if np.isnan(data).any():\n",
    "            print(f\"NaN values found in {label}\")\n",
    "        if np.isinf(data).any():\n",
    "            print(f\"Inf values found in {label}\")\n",
    "        else:\n",
    "            print(f\"No NaN or Inf values found in {label}\")\n",
    "\n",
    "  \n",
    "    for i in range(len(left_in_attleft_sm)):\n",
    "        left_in_attleft_sum[i] = zscore(left_in_attleft_sum[i], axis=0)\n",
    "        #left_in_attleft_sm[i] = np.nan_to_num(left_in_attleft_sm[i])  # Replace NaNs with 0\n",
    "        right_in_attleft_sum[i] = zscore(right_in_attleft_sum[i], axis=0)\n",
    "        #right_in_attleft_sm[i] = np.nan_to_num(right_in_attleft_sm[i])\n",
    "        attlay_attleft_sum[i] = zscore(attlay_attleft_sum[i], axis=0)\n",
    "        #attlay_attleft_sm[i] = np.nan_to_num(attlay_attleft_sm[i])\n",
    "\n",
    "    for i in range(len(left_in_attright_sm)):\n",
    "        left_in_attright_sum[i] = zscore(left_in_attright_sum[i], axis=0)\n",
    "        #left_in_attright_sm[i] = np.nan_to_num(left_in_attright_sm[i])\n",
    "        right_in_attright_sum[i] = zscore(right_in_attright_sum[i], axis=0)\n",
    "        #right_in_attright_sm[i] = np.nan_to_num(right_in_attright_sm[i])\n",
    "        attlay_attright_sum[i] = zscore(attlay_attright_sum[i], axis=0)\n",
    "        #attlay_attright_sm[i] = np.nan_to_num(attlay_attright_sm[i])\n",
    "\n",
    "    # print(\"\\n=== Checking for NaN or Inf Values ===\")\n",
    "    # check_nan_inf(left_in_attleft_sum, \"left_in_attleft_sum\")\n",
    "    # check_nan_inf(right_in_attleft_sum, \"right_in_attleft_sum\")\n",
    "    # check_nan_inf(attlay_attleft_sum, \"attlay_attleft_sum\")\n",
    "    # check_nan_inf(left_in_attright_sum, \"left_in_attright_sum\")\n",
    "    # check_nan_inf(right_in_attright_sum, \"right_in_attright_sum\")\n",
    "    # check_nan_inf(attlay_attright_sum, \"attlay_attright_sum\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(left_in_attleft_sm)):\n",
    "        left_in_attleft_sum[i] = detrend(left_in_attleft_sum[i])\n",
    "        right_in_attleft_sum[i] = detrend(right_in_attleft_sum[i])\n",
    "        attlay_attleft_sum[i] = detrend(attlay_attleft_sum[i])\n",
    "\n",
    "  \n",
    "    for i in range(len(left_in_attright_sm)):\n",
    "        left_in_attright_sum[i] = detrend(left_in_attright_sum[i])\n",
    "        right_in_attright_sum[i] = detrend(right_in_attright_sum[i])\n",
    "        attlay_attright_sum[i] = detrend(attlay_attright_sum[i])\n",
    "\n",
    "\n",
    "    print(\"\\n=== After Summing Over Neurons ===\")\n",
    "    print(\"left_in_attleft_sum shape:\", left_in_attleft_sum.shape)\n",
    "    print(\"right_in_attleft_sum shape:\", right_in_attleft_sum.shape)\n",
    "    print(\"attlay_attleft_sum shape:\", attlay_attleft_sum.shape)\n",
    "    \n",
    "\n",
    "#balance sampling from class pairs\n",
    "#standardise the data for mean 0 and std 1 to remove offsets \n",
    "#try linear detrend\n",
    "\n",
    "    n_samples = left_in_attleft_sum.shape[1]   ##change this for correct time \n",
    "    print(\"n_samples:\", n_samples)\n",
    "\n",
    "    dt = 0.002\n",
    "    sfreq = 1 / dt  # Sampling frequency\n",
    "\n",
    "    ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "    ch_types = ['eeg', 'eeg', 'eeg']\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    # Stack data into shape (n_trials, n_channels, n_samples)\n",
    "    data_left = np.stack([left_in_attleft_sum, right_in_attleft_sum, attlay_attleft_sum], axis=1)\n",
    "    data_right = np.stack([left_in_attright_sum, right_in_attright_sum, attlay_attright_sum], axis=1)\n",
    "\n",
    "    # Create events array\n",
    "    n_times = data_left.shape[2]  # Number of samples per trial\n",
    "    events_left = np.array([[i * n_times, 0, 1] for i in range(data_left.shape[0])])\n",
    "    events_right = np.array([[i * n_times, 0, 1] for i in range(data_right.shape[0])])\n",
    "\n",
    "    # Convert data into MNE Epochs\n",
    "    epochs_left = mne.EpochsArray(data_left, info, events=events_left, tmin=0)\n",
    "    epochs_right = mne.EpochsArray(data_right, info, events=events_right, tmin=0)\n",
    "\n",
    "    # Define channel indices for Granger causality\n",
    "    seeds = np.array([[0], [1]])\n",
    "    targets = np.array([[2], [2]])\n",
    "    indices = (seeds, targets)\n",
    "\n",
    "    # Compute Granger causality\n",
    "    gc_left = spectral_connectivity_epochs(\n",
    "        epochs_left, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    gc_right = spectral_connectivity_epochs(\n",
    "        epochs_right, method='gc', indices=indices, sfreq=sfreq,\n",
    "        fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    )\n",
    "\n",
    "    # Extract Granger causality data\n",
    "    gc_data_left = gc_left.get_data()\n",
    "    gc_data_right = gc_right.get_data()\n",
    "    freqs = gc_left.freqs\n",
    "\n",
    "    print(\"\\n=== Granger Causality Data ===\")\n",
    "    print(\"GC Left shape:\", gc_data_left.shape)\n",
    "    print(\"GC Right shape:\", gc_data_right.shape)\n",
    "\n",
    "    # Plot Granger causality results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].plot(freqs, gc_data_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[0].plot(freqs, gc_data_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[0].set_title(\"Attention Left - Dataset \" + str(file_number))\n",
    "    ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[0].set_ylabel(\"Granger Causality\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(freqs, gc_data_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    ax[1].plot(freqs, gc_data_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    ax[1].set_title(\"Attention Right - Dataset \" + str(file_number))\n",
    "    ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[1].set_ylabel(\"Granger Causality\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # #plotting the net gc\n",
    "    # indices_back = (targets, seeds)\n",
    "    # gc_left_back = spectral_connectivity_epochs(\n",
    "    #     epochs_left, method='gc', indices=indices_back, sfreq=sfreq,\n",
    "    #     fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    # )\n",
    "\n",
    "    # gc_right_back = spectral_connectivity_epochs(\n",
    "    #     epochs_right, method='gc', indices=indices_back, sfreq=sfreq,\n",
    "    #     fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    # )\n",
    "\n",
    "    # gc_data_left_back = gc_left_back.get_data()\n",
    "    # gc_data_right_back = gc_right_back.get_data()\n",
    "\n",
    "    # net_gc_left = gc_data_left - gc_data_left_back\n",
    "    # net_gc_right = gc_data_right - gc_data_right_back\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # ax[0].plot(freqs, net_gc_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    # ax[0].plot(freqs, net_gc_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    # ax[0].set_title(\"Attention Left - Dataset \" + str(file_number))\n",
    "    # ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    # ax[0].set_ylabel(\"Net Granger Causality\")\n",
    "    # ax[0].legend()\n",
    "\n",
    "    # ax[1].plot(freqs, net_gc_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    # ax[1].plot(freqs, net_gc_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    # ax[1].set_title(\"Attention Right - Dataset \" + str(file_number))\n",
    "    # ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    # ax[1].set_ylabel(\"Net Granger Causality\")\n",
    "    # ax[1].legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # #time reversal (unsure if this is phsyically meaningful)\n",
    "\n",
    "    #     # Define channel indices for Granger causality\n",
    "    # seeds = np.array([[0], [1]])\n",
    "    # targets = np.array([[2], [2]])\n",
    "    # indices = (seeds, targets)\n",
    "\n",
    "    # # Compute Granger causality\n",
    "    # gc_left = spectral_connectivity_epochs(\n",
    "    #     epochs_left, method='gc_tr', indices=indices, sfreq=sfreq,\n",
    "    #     fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    # )\n",
    "\n",
    "    # gc_right = spectral_connectivity_epochs(\n",
    "    #     epochs_right, method='gc_tr', indices=indices, sfreq=sfreq,\n",
    "    #     fmin=0.5, fmax=245.0, tmin=0.0, tmax=(n_times - 1) / sfreq, gc_n_lags=5\n",
    "    # )\n",
    "\n",
    "    # # Extract Granger causality data\n",
    "    # gc_data_left = gc_left.get_data()\n",
    "    # gc_data_right = gc_right.get_data()\n",
    "    # freqs = gc_left.freqs\n",
    "\n",
    "    # print(\"\\n=== Granger Causality Data ===\")\n",
    "    # print(\"GC Left shape:\", gc_data_left.shape)\n",
    "    # print(\"GC Right shape:\", gc_data_right.shape)\n",
    "\n",
    "    # # Plot Granger causality results\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # ax[0].plot(freqs, gc_data_left[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    # ax[0].plot(freqs, gc_data_left[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    # ax[0].set_title(\"Attention Left (LA - trLA) - Dataset \" + str(file_number))\n",
    "    # ax[0].set_xlabel(\"Frequency (Hz)\")\n",
    "    # ax[0].set_ylabel(\"Granger Causality\")\n",
    "    # ax[0].legend()\n",
    "\n",
    "    # ax[1].plot(freqs, gc_data_right[0, :], label=\"GC Left -> Attention\", color='r')\n",
    "    # ax[1].plot(freqs, gc_data_right[1, :], label=\"GC Right -> Attention\", color='k')\n",
    "    # ax[1].set_title(\"Attention Right (RA - trRA) - Dataset \" + str(file_number))\n",
    "    # ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    # ax[1].set_ylabel(\"Granger Causality\")\n",
    "    # ax[1].legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

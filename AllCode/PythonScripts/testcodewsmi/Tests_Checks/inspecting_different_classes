import numpy as np
import mne
import pickle
import matplotlib.pyplot as plt
from nice.algorithms.connectivity import epochs_compute_wsmi
np.set_printoptions(threshold=100)  # Default threshold
from scipy.stats import pearsonr
from scipy.stats import zscore
from scipy.signal import detrend

#seems to be selecting indices correctly, but wsmi isnt discriminating between left and right attention


# i_values = [1, 2, 4, 8, 14, 15, 20, 23]
i_values = [4]
#for data set 3, error with left, but larger wsmi - seems indicative of a problem with the calculation
# i_values = [1]
# Initialize results dictionary for 10 datasets
results = {}
for store in i_values:
    results[f'dataset_{store}'] = {
        'attention_left': {
            'larger wsmi': [],
            'larger pearson': [],
      
        },
        'attention_right': {
            'larger wsmi': [],
            'larger pearson': [],
        
        }
    }


for file_number in i_values:
    # Load data
    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'
    data = pickle.load(open(file_path, 'rb'))

    attention_labels = data['label_attend'][0]
    print("attend", attention_labels[:10])
    label_left = data['label_left'][0]
    print("label_left", label_left[:10])
    label_right = data['label_right'][0]
    print("label_right", label_right[:10])
    attend_01 = data['attend'][0]
    print ("attend01", attend_01[:10])


    #not filtered for omitted trials 
    left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right 
    right_input_LFP = data['LFP'][0][1]  # Right input
    attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention 
    omitted = data["omit"][0]
    # print("omitted", omitted[:10])

    #subset further based on attention
    left_indices = np.where((label_left == 2) & (label_right ==17) & (omitted == 0) & (attend_01 == 0))[0]   #e.g. only want the trials where attention is left and not omitted and label left is 0
    right_indices = np.where((label_left == 2) & (label_right == 17) & (omitted == 0) & (attend_01 == 1))[0]   #e.g. only want trials attention left not om and label left is 0

    print("attend_01 left indices", attend_01[left_indices])
    print("attend_01 right indices", attend_01[right_indices])

    print("label_left left indices = ", label_left[left_indices])
    print("label_left right indices = ", label_left[right_indices])
    print("label_right left indices = ", label_right[left_indices])
    print("label_right right indices = ", label_right[right_indices])



    left_input_LFP_om_left = left_input_LFP[left_indices]
    left_input_LFP_om_left_relevant = left_input_LFP_om_left[:, :]
    fig, axs = plt.subplots(len(left_input_LFP_om_left_relevant), 1, figsize=(5, 6), sharex=True)
    if len(left_input_LFP_om_left_relevant) == 1:
        axs.plot(left_input_LFP_om_left_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(left_input_LFP_om_left_relevant)):
            axs[i].plot(left_input_LFP_om_left_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    right_input_LFP_om_left = right_input_LFP[left_indices]
    right_input_LFP_om_left_relevant = right_input_LFP_om_left[:, :]
    fig, axs = plt.subplots(len(right_input_LFP_om_left_relevant), 1, figsize=(5, 6), sharex=True)
    if len(right_input_LFP_om_left_relevant) == 1:
        axs.plot(right_input_LFP_om_left_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(right_input_LFP_om_left_relevant)):
            axs[i].plot(right_input_LFP_om_left_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    left_input_LFP_om_right = left_input_LFP[right_indices]
    left_input_LFP_om_right_relevant = left_input_LFP_om_right[:, :]
    fig, axs = plt.subplots(len(left_input_LFP_om_right_relevant), 1, figsize=(5, 6), sharex=True)
    if len(left_input_LFP_om_right_relevant) == 1:
        axs.plot(left_input_LFP_om_right_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(left_input_LFP_om_right_relevant)):
            axs[i].plot(left_input_LFP_om_right_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    right_input_LFP_om_right = right_input_LFP[right_indices]
    right_input_LFP_om_right_relevant = right_input_LFP_om_right[:, :]
    fig, axs = plt.subplots(len(right_input_LFP_om_right_relevant), 1, figsize=(5, 6), sharex=True)
    if len(right_input_LFP_om_right_relevant) == 1:
        axs.plot(right_input_LFP_om_right_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(right_input_LFP_om_right_relevant)):
            axs[i].plot(right_input_LFP_om_right_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    
    left_input_LFP_om_left = left_input_LFP[left_indices]
    left_input_LFP_om_left_relevant = left_input_LFP_om_left[:, 100:350]

    
    right_input_LFP_om_left = right_input_LFP[left_indices]
    right_input_LFP_om_left_relevant = right_input_LFP_om_left[:, 100:350]


    left_input_LFP_om_right = left_input_LFP[right_indices]
    left_input_LFP_om_right_relevant = left_input_LFP_om_right[:, 100:350]

    right_input_LFP_om_right = right_input_LFP[right_indices]
    right_input_LFP_om_right_relevant = right_input_LFP_om_right[:, 100:350]


    attention_LFP_om_left = attention_LFP[left_indices]
    attention_LFP_om_left_relevant = attention_LFP_om_left[:, 100:350]
    attention_LFP_om_right = attention_LFP[right_indices]
    attention_LFP_om_right_relevant = attention_LFP_om_right[:, 100:350]

    
    for i in range(len(left_input_LFP_om_left_relevant)):
        left_input_LFP_om_left_relevant[i] = zscore(left_input_LFP_om_left_relevant[i])
        right_input_LFP_om_left_relevant[i] = zscore(right_input_LFP_om_left_relevant[i])
        attention_LFP_om_left_relevant[i] = zscore(attention_LFP_om_left_relevant[i])

    for i in range(len(left_input_LFP_om_left_relevant)):
        left_input_LFP_om_left_relevant[i] = detrend(left_input_LFP_om_left_relevant[i])
        right_input_LFP_om_left_relevant[i] = detrend(right_input_LFP_om_left_relevant[i])
        attention_LFP_om_left_relevant[i] = detrend(attention_LFP_om_left_relevant[i])

    for i in range(len(left_input_LFP_om_right_relevant)):
        left_input_LFP_om_right_relevant[i] = zscore(left_input_LFP_om_right_relevant[i])
        right_input_LFP_om_right_relevant[i] = zscore(right_input_LFP_om_right_relevant[i])
        attention_LFP_om_right_relevant[i] = zscore(attention_LFP_om_right_relevant[i])

    for i in range(len(left_input_LFP_om_right_relevant)):
        left_input_LFP_om_right_relevant[i] = detrend(left_input_LFP_om_right_relevant[i])
        right_input_LFP_om_right_relevant[i] = detrend(right_input_LFP_om_right_relevant[i])
        attention_LFP_om_right_relevant[i] = detrend(attention_LFP_om_right_relevant[i])

    
    #attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]
    #label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]
    #label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]
    #omitted [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]

        left_input_LFP_om_left = left_input_LFP[left_indices]
    left_input_LFP_om_left_relevant = left_input_LFP_om_left[:, :]
    fig, axs = plt.subplots(len(left_input_LFP_om_left_relevant), 1, figsize=(5, 6), sharex=True)
    if len(left_input_LFP_om_left_relevant) == 1:
        axs.plot(left_input_LFP_om_left_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(left_input_LFP_om_left_relevant)):
            axs[i].plot(left_input_LFP_om_left_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    right_input_LFP_om_left = right_input_LFP[left_indices]
    right_input_LFP_om_left_relevant = right_input_LFP_om_left[:, :]
    fig, axs = plt.subplots(len(right_input_LFP_om_left_relevant), 1, figsize=(5, 6), sharex=True)
    if len(right_input_LFP_om_left_relevant) == 1:
        axs.plot(right_input_LFP_om_left_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(right_input_LFP_om_left_relevant)):
            axs[i].plot(right_input_LFP_om_left_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    left_input_LFP_om_right = left_input_LFP[right_indices]
    left_input_LFP_om_right_relevant = left_input_LFP_om_right[:, :]
    fig, axs = plt.subplots(len(left_input_LFP_om_right_relevant), 1, figsize=(5, 6), sharex=True)
    if len(left_input_LFP_om_right_relevant) == 1:
        axs.plot(left_input_LFP_om_right_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(left_input_LFP_om_right_relevant)):
            axs[i].plot(left_input_LFP_om_right_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    right_input_LFP_om_right = right_input_LFP[right_indices]
    right_input_LFP_om_right_relevant = right_input_LFP_om_right[:, :]
    fig, axs = plt.subplots(len(right_input_LFP_om_right_relevant), 1, figsize=(5, 6), sharex=True)
    if len(right_input_LFP_om_right_relevant) == 1:
        axs.plot(right_input_LFP_om_right_relevant[0, :])
        axs.set_title('Trial 1')
    else:
        for i in range(len(right_input_LFP_om_right_relevant)):
            axs[i].plot(right_input_LFP_om_right_relevant[i, :])
            axs[i].set_title(f'Trial {i+1}')
    plt.xlabel('Time (ms)')
    plt.tight_layout()
    plt.show()

    
#can try smoothing here
    from scipy.ndimage import gaussian_filter1d

    def smooth_with_gaussian(data, sigma):
        return gaussian_filter1d(data, sigma=sigma, axis=1) 

    sigma = 1  
    attention_LFP_om_left_relevant = smooth_with_gaussian(attention_LFP_om_left_relevant, sigma=sigma) 
    attention_LFP_om_right_relevant = smooth_with_gaussian(attention_LFP_om_right_relevant, sigma=sigma) 

    #plotting the mean across trials of all three data sets for when attention is left and right
    fig, ax = plt.subplots(1, 2, figsize=(12, 6))
    
    #plot for Attention Left
    ax[0].plot(np.mean(left_input_LFP_om_left_relevant / np.max(left_input_LFP_om_left_relevant), axis=0), label="Left Input")
    ax[0].plot(np.mean(right_input_LFP_om_left_relevant/ np.max(right_input_LFP_om_left_relevant), axis=0), label="Right Input")
    ax[0].plot(np.mean(attention_LFP_om_left_relevant/np.max(attention_LFP_om_left_relevant), axis=0), label="Attention Layer")
    ax[0].set_title("Attention Left")
    ax[0].set_xlabel("Time (ms)")
    ax[0].set_ylabel("LFP")
    ax[0].legend()
    
    #plot for Attention Right
    ax[1].plot(np.mean(left_input_LFP_om_right_relevant / np.max(left_input_LFP_om_right_relevant), axis=0), label="Left Input")
    ax[1].plot(np.mean(right_input_LFP_om_right_relevant / np.max(right_input_LFP_om_right_relevant), axis=0), label="Right Input")
    ax[1].plot(np.mean(attention_LFP_om_right_relevant / np.max(attention_LFP_om_right_relevant), axis=0), label="Attention Layer")
    ax[1].set_title("Attention Right")
    ax[1].set_xlabel("Time (ms)")
    ax[1].set_ylabel("LFP")
    ax[1].legend()



    n_times = left_input_LFP_om_left_relevant.shape[1] ##=250
    print("n_samples", n_times)


    dt = 0.002
    sfreq = 1 / dt




    ch_names = ['left_input', 'right_input', 'attention_layer']
    ch_types = ['eeg', 'eeg', 'eeg']
    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)


    #reshaping data for attention left
    raw_data_left = np.concatenate([
        left_input_LFP_om_left_relevant, 
        right_input_LFP_om_left_relevant, 
        attention_LFP_om_left_relevant 
    ], axis=0)  # Concatenate along time axis

    print("raw_data_left shape =", raw_data_left.shape)  
    # Reshape into (n_channels, n_samples)
    raw_data_left = raw_data_left.reshape(3, -1)  
    print('raw data left reshaped =', raw_data_left.shape)  
    print('raw data left, attending left, trial 0:', raw_data_left[0, :n_times])
    #raw data left, attending left, trial 0: [ 0.          8.30495834  6.72716999 ... 75.45306396 79.49226379, 71.67674255]
    #

    raw_left = mne.io.RawArray(raw_data_left, info)
    print("raw_data_left =", raw_left)
    



    #reshaping date for attention right 
    raw_data_right = np.concatenate([
        left_input_LFP_om_right_relevant,
        right_input_LFP_om_right_relevant,
        attention_LFP_om_right_relevant 
    ], axis=0)

    raw_data_right = raw_data_right.reshape(3, -1)
  
    raw_right = mne.io.RawArray(raw_data_right, info)

    #Creating RawArray with float64 data, n_channels=3, n_times=268000
    #    Range : 0 ... 267999 =      0.000 ...   535.998 secs     why this time? seems to be out by 0.002 seconds of what would be expected

    #defininf event objects, arrays like [0,0,1], [500, 0, 1], [1000, 0, 1] etc
    events_left = np.array([[i * n_times, 0, 1] for i in range(len(left_input_LFP_om_left_relevant))])
    events_right = np.array([[i * n_times, 0, 1] for i in range(len(right_input_LFP_om_right_relevant))])

    
    print("events_left", events_left[:4])

    epochs_left = mne.Epochs(raw_left, events_left, event_id={'Trial': 1}, tmin=0, tmax =  0.35,  baseline=None, preload=True)
    epochs_right = mne.Epochs(raw_right, events_right, event_id={'Trial': 1}, tmin=0, tmax = 0.35, baseline=None, preload=True)
    print('----------------', (n_times - 1)/ sfreq)

    print("epochs_left", epochs_left)
    epochs_left.plot(n_epochs=5, n_channels=3, scalings = 'auto', title="Attention Left")
    plt.show()

    kernel = 3
    taus = [8, 16, 32, 64]  # in ms
    wsmi_results = {'left': {}, 'right': {}}

    for tau in taus:
        tau_samples = int(tau / (1000 / sfreq))
        print(f"tau_samples for {tau}: {tau_samples}")
        
        wsmi_left, _, _, _ = epochs_compute_wsmi(
            epochs_left, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}
        )
        wsmi_results['left'][tau] = wsmi_left
        #this containts the data for wsmi at a given tau given attending left. 

        wsmi_right, _, _, _ = epochs_compute_wsmi(
            epochs_right, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}
        )
        wsmi_results['right'][tau] = wsmi_right

    wsmi_left_input_attleft = []  #wSMI for left input vs attention layer (attention left)
    wsmi_right_input_attleft = []  #wSMI for right input vs attention layer (attention left)
    wsmi_left_input_attright = []  #wSMI for left input vs attention layer (attention right)
    wsmi_right_input_attright = []  #wSMI for right input vs attention layer (attention right)

    #average wSMI for each τ for each condition
    for tau in taus:
        # For attention left
        wsmi_left_input_attleft.append(np.mean(wsmi_results['left'][tau][0, 2, :]))  # Left input vs attention layer
        wsmi_right_input_attleft.append(np.mean(wsmi_results['left'][tau][1, 2, :]))  # Right input vs attention layer

        # For attention right
        wsmi_left_input_attright.append(np.mean(wsmi_results['right'][tau][0, 2, :]))  # Left input vs attention layer
        wsmi_right_input_attright.append(np.mean(wsmi_results['right'][tau][1, 2, :]))  # Right input vs attention layer

    for tau in taus:
        if wsmi_left_input_attleft[taus.index(tau)] > wsmi_right_input_attleft[taus.index(tau)]:
            results[f'dataset_{file_number}']['attention_left']['larger wsmi'].append(0)
        else:
            results[f'dataset_{file_number}']['attention_left']['larger wsmi'].append(1)

        if wsmi_left_input_attright[taus.index(tau)] > wsmi_right_input_attright[taus.index(tau)]:
            results[f'dataset_{file_number}']['attention_right']['larger wsmi'].append(0)
        else:
            results[f'dataset_{file_number}']['attention_right']['larger wsmi'].append(1)


    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

    #left subplot
    axs[0].scatter(taus, wsmi_left_input_attleft, label="Left Input vs Attention Layer", marker="x",color = 'r', s=100)
    axs[0].scatter(taus, wsmi_right_input_attleft, label="Right Input vs Attention Layer", marker="x",color = 'k', s=100)
    axs[0].set_title("Attention Left", fontsize=14)
    axs[0].set_xlabel("τ (ms)", fontsize=12)
    axs[0].set_ylabel("Average wSMI", fontsize=12)
    axs[0].legend()
    axs[0].grid(False)

    #right subplot
    axs[1].scatter(taus, wsmi_left_input_attright, label="Left Input vs Attention Layer", marker="x", color = 'r', s=100)
    axs[1].scatter(taus, wsmi_right_input_attright, label="Right Input vs Attention Layer", marker="x",color = 'k', s=100)
    axs[1].set_title("Attention Right", fontsize=14)
    axs[1].set_xlabel("τ (ms)", fontsize=12)
    axs[1].legend()
    axs[1].grid(False)

    plt.tight_layout()
    plt.show()


    # print('wsmi_results.shape', wsmi_results['left'][8].shape)
    # #wsmi_results.shape (3, 3, 468), so get a 3x3 for each trial. note that values for performing a single trial are different to 
    # #extracting the wsmi value of the first trial from wsmi_results. unsure why. 

    # for tau_to_check in taus:
    #     wsmi_first_trial_left = wsmi_results['left'][tau_to_check][:, :, 0] 
    #     print(f"wSMI matrix for the first trial (attention left) at tau={tau_to_check} ms:\n", wsmi_first_trial_left)


    attleft_pearson_left = []
    attleft_pearson_right = []
    attright_pearson_left = []
    attright_pearson_right = []

    for i in range(len(left_indices)):
        corr_left, _ = pearsonr(left_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])
        attleft_pearson_left.append(corr_left)
        corr_right, _ = pearsonr(right_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])
        attleft_pearson_right.append(corr_right)

    for i in range(len(right_indices)):
        corr_left, _ = pearsonr(left_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])
        attright_pearson_left.append(corr_left)
        corr_right, _ = pearsonr(right_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])
        attright_pearson_right.append(corr_right)

    mean_corr_left_attleft = np.mean(attleft_pearson_left)
    mean_corr_right_attleft = np.mean(attleft_pearson_right)
    mean_corr_left_attright = np.mean(attright_pearson_left)
    mean_corr_right_attright = np.mean(attright_pearson_right)


    if mean_corr_left_attleft > mean_corr_right_attleft:
        results[f'dataset_{file_number}']['attention_left']['larger pearson'].append(0)
    else:
        results[f'dataset_{file_number}']['attention_left']['larger pearson'].append(1)

    if mean_corr_left_attright > mean_corr_right_attright:
        results[f'dataset_{file_number}']['attention_right']['larger pearson'].append(0)
    else:
        results[f'dataset_{file_number}']['attention_right']['larger pearson'].append(1)

    
    x = [0, 1]
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    axs[0].scatter(x, [mean_corr_left_attleft, mean_corr_right_attleft],
                label="Attention Left", color='k', marker='x', s=100)
    axs[1].scatter(x, [mean_corr_left_attright, mean_corr_right_attright],
                label="Attention Right", color='k', marker='x', s=100)

    for ax in axs:
        ax.set_xticks(x)
        ax.set_xticklabels(['left', 'right'])
        ax.set_xlim(-0.7, 1.7)

    axs[0].set_title("Attention Left", fontsize=14)
    axs[1].set_title("Attention Right", fontsize=14)
    axs[0].set_ylabel("Mean Pearson Correlation", fontsize=12)
    axs[1].set_ylabel("Mean Pearson Correlation", fontsize=12)

    axs[0].grid(False)
    axs[1].grid(False)

    plt.tight_layout()
    plt.show()

       
print(results)
   

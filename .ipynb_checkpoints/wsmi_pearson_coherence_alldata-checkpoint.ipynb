{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb68c42-8072-4752-b0d2-542a658234ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\externals\\tempita\\__init__.py:35: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n"
     ]
    }
   ],
   "source": [
    "#LFP data - wsmi and pearson\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nice.algorithms.connectivity import epochs_compute_wsmi\n",
    "np.set_printoptions(threshold=100)  # Default threshold\n",
    "\n",
    "i_values = [1, 2, 3, 4, 8, 14, 15, 20, 23]\n",
    "for i in i_values:\n",
    "    # Load data\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{i}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    attention_labels = data['label_attend'][0]\n",
    "    print(\"attend\", attention_labels[:10])\n",
    "    label_left = data['label_left'][0]\n",
    "    print(\"label_left\", label_left[:10])\n",
    "    label_right = data['label_right'][0]\n",
    "    print(\"label_right\", label_right[:10])\n",
    "    attend_01 = data['attend'][0]\n",
    "    print (\"attend01\", attend_01[:10])\n",
    "\n",
    "\n",
    "    #not filtered for omitted trials \n",
    "    left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right \n",
    "    right_input_LFP = data['LFP'][0][1]  # Right input\n",
    "    attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention \n",
    "    omitted = data[\"omit\"][0]\n",
    "    # print(\"omitted\", omitted[:10])\n",
    "\n",
    "    #subset further based on attention\n",
    "    left_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 0))[0]\n",
    "    right_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 1))[0]\n",
    "\n",
    "    left_input_LFP_om_left = left_input_LFP[left_indices]\n",
    "    left_input_LFP_om_left_relevant = left_input_LFP_om_left[:, 100:350]\n",
    "    #left_input_LFP_om_right_relevant (468, 250)\n",
    "\n",
    "    right_input_LFP_om_left = right_input_LFP[left_indices]\n",
    "    right_input_LFP_om_left_relevant = right_input_LFP_om_left[:, 100:350]\n",
    "\n",
    "    left_input_LFP_om_right = left_input_LFP[right_indices]\n",
    "    left_input_LFP_om_right_relevant = left_input_LFP_om_right[:, 100:350]\n",
    "\n",
    "    right_input_LFP_om_right = right_input_LFP[right_indices]\n",
    "    right_input_LFP_om_right_relevant = right_input_LFP_om_right[:, 100:350]\n",
    "\n",
    "\n",
    "    attention_LFP_om_left = attention_LFP[left_indices]\n",
    "    attention_LFP_om_left_relevant = attention_LFP_om_left[:, 100:350]\n",
    "    attention_LFP_om_right = attention_LFP[right_indices]\n",
    "    attention_LFP_om_right_relevant = attention_LFP_om_right[:, 100:350]\n",
    "\n",
    "    #attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]\n",
    "    #label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]\n",
    "    #label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]\n",
    "    #omitted [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
    "\n",
    "    #plotting the mean across trials of all three data sets for when attention is left and right\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    #plot for Attention Left\n",
    "    ax[0].plot(np.mean(left_input_LFP_om_left_relevant / np.max(left_input_LFP_om_left_relevant), axis=0), label=\"Left Input\")\n",
    "    ax[0].plot(np.mean(right_input_LFP_om_left_relevant/ np.max(right_input_LFP_om_left_relevant), axis=0), label=\"Right Input\")\n",
    "    ax[0].plot(np.mean(attention_LFP_om_left_relevant/np.max(attention_LFP_om_left_relevant), axis=0), label=\"Attention Layer\")\n",
    "    ax[0].set_title(\"Attention Left\")\n",
    "    ax[0].set_xlabel(\"Time (ms)\")\n",
    "    ax[0].set_ylabel(\"LFP\")\n",
    "    ax[0].legend()\n",
    "    \n",
    "    #plot for Attention Right\n",
    "    ax[1].plot(np.mean(left_input_LFP_om_right_relevant / np.max(left_input_LFP_om_right_relevant), axis=0), label=\"Left Input\")\n",
    "    ax[1].plot(np.mean(right_input_LFP_om_right_relevant / np.max(right_input_LFP_om_right_relevant), axis=0), label=\"Right Input\")\n",
    "    ax[1].plot(np.mean(attention_LFP_om_right_relevant / np.max(attention_LFP_om_right_relevant), axis=0), label=\"Attention Layer\")\n",
    "    ax[1].set_title(\"Attention Right\")\n",
    "    ax[1].set_xlabel(\"Time (ms)\")\n",
    "    ax[1].set_ylabel(\"LFP\")\n",
    "    ax[1].legend()\n",
    "\n",
    "\n",
    "\n",
    "    n_times = left_input_LFP_om_left_relevant.shape[1] ##=250\n",
    "    print(\"n_samples\", n_times)\n",
    "\n",
    "\n",
    "    dt = 0.002\n",
    "    sfreq = 1 / dt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "    ch_types = ['eeg', 'eeg', 'eeg']\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "\n",
    "    #reshaping data for attention left\n",
    "    raw_data_left = np.concatenate([\n",
    "        left_input_LFP_om_left_relevant, \n",
    "        right_input_LFP_om_left_relevant, \n",
    "        attention_LFP_om_left_relevant\n",
    "    ], axis=0)  # Concatenate along time axis\n",
    "\n",
    "    # Reshape into (n_channels, n_samples)\n",
    "    raw_data_left = raw_data_left.reshape(3, -1)  \n",
    "    print('raw data left shape:', raw_data_left.shape)  \n",
    "    print('raw data left, attending left, trial 0:', raw_data_left[0, :n_times])\n",
    "    #raw data left, attending left, trial 0: [ 0.          8.30495834  6.72716999 ... 75.45306396 79.49226379, 71.67674255]\n",
    "    #\n",
    "\n",
    "    raw_left = mne.io.RawArray(raw_data_left, info)\n",
    "\n",
    "\n",
    "\n",
    "    #reshaping date for attention right \n",
    "    raw_data_right = np.concatenate([\n",
    "        left_input_LFP_om_right_relevant,\n",
    "        right_input_LFP_om_right_relevant,\n",
    "        attention_LFP_om_right_relevant\n",
    "    ], axis=0)\n",
    "\n",
    "    raw_data_right = raw_data_right.reshape(3, -1)\n",
    "    print('raw data right shape:', raw_data_right.shape)\n",
    "    print('raw data right, attending right, first right attending trial:', raw_data_right[1, 2*n_times:3*n_times])\n",
    "    #raw data right, attending right, first right attending trial: [  0.          16.3247776   16.00920868 ... 126.37789154 154.798873,  140.4855957 ]\n",
    "    #this is good, it is the same as in the single trial case, and seems to be stacking correctly\n",
    "\n",
    "\n",
    "    raw_right = mne.io.RawArray(raw_data_right, info)\n",
    "\n",
    "    #Creating RawArray with float64 data, n_channels=3, n_times=268000\n",
    "    #    Range : 0 ... 267999 =      0.000 ...   535.998 secs     why this time? seems to be out by 0.002 seconds of what would be expected\n",
    "\n",
    "    #defininf event objects, arrays like [0,0,1], [500, 0, 1], [1000, 0, 1] etc\n",
    "    events_left = np.array([[i * n_times, 0, 1] for i in range(len(left_input_LFP_om_left_relevant))])\n",
    "    events_right = np.array([[i * n_times, 0, 1] for i in range(len(right_input_LFP_om_right_relevant))])\n",
    "\n",
    "\n",
    "    print(\"events_left\", events_left[:4])\n",
    "\n",
    "    epochs_left = mne.Epochs(raw_left, events_left, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "    epochs_right = mne.Epochs(raw_right, events_right, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "\n",
    "    kernel = 3\n",
    "    taus = [8, 16, 32, 64]  # in ms\n",
    "    wsmi_results = {'left': {}, 'right': {}}\n",
    "\n",
    "    for tau in taus:\n",
    "        tau_samples = int(tau / (1000 / sfreq))\n",
    "        print(f\"tau_samples for {tau}: {tau_samples}\")\n",
    "        \n",
    "        wsmi_left, _, _, _ = epochs_compute_wsmi(\n",
    "            epochs_left, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "        )\n",
    "        wsmi_results['left'][tau] = wsmi_left\n",
    "        #this containts the data for wsmi at a given tau given attending left. \n",
    "\n",
    "        wsmi_right, _, _, _ = epochs_compute_wsmi(\n",
    "            epochs_right, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "        )\n",
    "        wsmi_results['right'][tau] = wsmi_right\n",
    "\n",
    "    wsmi_left_input_attleft = []  #wSMI for left input vs attention layer (attention left)\n",
    "    wsmi_right_input_attleft = []  #wSMI for right input vs attention layer (attention left)\n",
    "    wsmi_left_input_attright = []  #wSMI for left input vs attention layer (attention right)\n",
    "    wsmi_right_input_attright = []  #wSMI for right input vs attention layer (attention right)\n",
    "\n",
    "    #average wSMI for each Ï„ for each condition\n",
    "    for tau in taus:\n",
    "        # For attention left\n",
    "        wsmi_left_input_attleft.append(np.mean(wsmi_results['left'][tau][0, 2, :]))  # Left input vs attention layer\n",
    "        wsmi_right_input_attleft.append(np.mean(wsmi_results['left'][tau][1, 2, :]))  # Right input vs attention layer\n",
    "\n",
    "        # For attention right\n",
    "        wsmi_left_input_attright.append(np.mean(wsmi_results['right'][tau][0, 2, :]))  # Left input vs attention layer\n",
    "        wsmi_right_input_attright.append(np.mean(wsmi_results['right'][tau][1, 2, :]))  # Right input vs attention layer\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "    #left subplot\n",
    "    axs[0].scatter(taus, wsmi_left_input_attleft, label=\"Left Input vs Attention Layer\", marker=\"x\",color = 'r', s=100)\n",
    "    axs[0].scatter(taus, wsmi_right_input_attleft, label=\"Right Input vs Attention Layer\", marker=\"x\",color = 'k', s=100)\n",
    "    axs[0].set_title(\"Attention Left\", fontsize=14)\n",
    "    axs[0].set_xlabel(\"Ï„ (ms)\", fontsize=12)\n",
    "    axs[0].set_ylabel(\"Average wSMI\", fontsize=12)\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(False)\n",
    "\n",
    "    #right subplot\n",
    "    axs[1].scatter(taus, wsmi_left_input_attright, label=\"Left Input vs Attention Layer\", marker=\"x\", color = 'r', s=100)\n",
    "    axs[1].scatter(taus, wsmi_right_input_attright, label=\"Right Input vs Attention Layer\", marker=\"x\",color = 'k', s=100)\n",
    "    axs[1].set_title(\"Attention Right\", fontsize=14)\n",
    "    axs[1].set_xlabel(\"Ï„ (ms)\", fontsize=12)\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print('wsmi_results.shape', wsmi_results['left'][8].shape)\n",
    "    #wsmi_results.shape (3, 3, 468), so get a 3x3 for each trial. note that values for performing a single trial are different to \n",
    "    #extracting the wsmi value of the first trial from wsmi_results. unsure why. \n",
    "\n",
    "    for tau_to_check in taus:\n",
    "        wsmi_first_trial_left = wsmi_results['left'][tau_to_check][:, :, 0] \n",
    "        print(f\"wSMI matrix for the first trial (attention left) at tau={tau_to_check} ms:\\n\", wsmi_first_trial_left)\n",
    "\n",
    "\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    attleft_pearson_left = []\n",
    "    attleft_pearson_right = []\n",
    "    attright_pearson_left = []\n",
    "    attright_pearson_right = []\n",
    "\n",
    "    for i in range(len(left_indices)):\n",
    "        corr_left, _ = pearsonr(left_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])\n",
    "        attleft_pearson_left.append(corr_left)\n",
    "        corr_right, _ = pearsonr(right_input_LFP_om_left_relevant[i], attention_LFP_om_left_relevant[i])\n",
    "        attleft_pearson_right.append(corr_right)\n",
    "\n",
    "    for i in range(len(right_indices)):\n",
    "        corr_left, _ = pearsonr(left_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])\n",
    "        attright_pearson_left.append(corr_left)\n",
    "        corr_right, _ = pearsonr(right_input_LFP_om_right_relevant[i], attention_LFP_om_right_relevant[i])\n",
    "        attright_pearson_right.append(corr_right)\n",
    "\n",
    "    mean_corr_left_attleft = np.mean(attleft_pearson_left)\n",
    "    mean_corr_right_attleft = np.mean(attleft_pearson_right)\n",
    "    mean_corr_left_attright = np.mean(attright_pearson_left)\n",
    "    mean_corr_right_attright = np.mean(attright_pearson_right)\n",
    "\n",
    "    print(\"mean correlation for left_attleft\", mean_corr_left_attleft)\n",
    "    print(\"mean correlation for right_attleft\", mean_corr_right_attleft)\n",
    "    print(\"mean correlation for left_attright\", mean_corr_left_attright)\n",
    "    print(\"mean correlation for right_attright\", mean_corr_right_attright)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    x = [0, 1]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].scatter(x, [mean_corr_left_attleft, mean_corr_right_attleft],\n",
    "                label=\"Attention Left\", color='k', marker='x', s=100)\n",
    "    axs[1].scatter(x, [mean_corr_left_attright, mean_corr_right_attright],\n",
    "                label=\"Attention Right\", color='k', marker='x', s=100)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['left', 'right'])\n",
    "        ax.set_xlim(-0.7, 1.7)\n",
    "\n",
    "    axs[0].set_title(\"Attention Left\", fontsize=14)\n",
    "    axs[1].set_title(\"Attention Right\", fontsize=14)\n",
    "    axs[0].set_ylabel(\"Mean Pearson Correlation\", fontsize=12)\n",
    "    axs[1].set_ylabel(\"Mean Pearson Correlation\", fontsize=12)\n",
    "\n",
    "    axs[0].grid(False)\n",
    "    axs[1].grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f6a7f-0a33-4f6b-be6b-8e3c3558c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spiking data - wsmi and pearson\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nice.algorithms.connectivity import epochs_compute_wsmi\n",
    "np.set_printoptions(threshold=100)  # Default threshold\n",
    "mne.set_log_level('WARNING')  # This will hide INFO messages\n",
    "\n",
    "\n",
    "i_values = [1, 2, 3, 4, 8, 14, 15, 20, 23]\n",
    "for i in i_values:\n",
    "    # Load data\n",
    "\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{i}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    left_input_SP = data['SP'][0][0] \n",
    "    right_input_SP = data['SP'][0][1]\n",
    "    attention_SP = data['SP'][0][2]\n",
    "    label_left = data['label_left'][0]\n",
    "    label_right = data['label_right'][0]\n",
    "    # left_input_SP (2032, 500, 160)\n",
    "    # right_input_SP (2032, 500, 160)\n",
    "    # attention_SP (2032, 500, 80)\n",
    "    \n",
    "\n",
    "    # attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "    # attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "\n",
    "    attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0))[0]\n",
    "    attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0))[0]\n",
    "\n",
    "    left_input_attendingleft_t = left_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    right_input_attendingleft_t = right_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingleft_t = attention_SP[attend_left_not_omitted, 100:350, :]\n",
    "\n",
    "    left_input_attendingright_t = left_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    right_input_attendingright_t = right_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingright_t = attention_SP[attend_right_not_omitted, 100:350, :]\n",
    "\n",
    "    #eft_input_attendingleft_t (468, 250, 160) (80 for attention)\n",
    "    #left_input_attendingright_t (536, 250, 160) (80 for attention)\n",
    "\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "    def smooth_with_gaussian(data, sigma=3):\n",
    "        return gaussian_filter1d(data, sigma=sigma, axis=1) \n",
    "\n",
    "    sigma = 2\n",
    "\n",
    "    left_in_attleft_sm = smooth_with_gaussian(left_input_attendingleft_t, sigma=sigma) \n",
    "    right_in_attleft_sm = smooth_with_gaussian(right_input_attendingleft_t, sigma=sigma) \n",
    "    attlay_attleft_sm = smooth_with_gaussian(attention_layer_attendingleft_t, sigma=sigma) \n",
    "\n",
    "    left_in_attright_sm = smooth_with_gaussian(left_input_attendingright_t, sigma=sigma) \n",
    "    right_in_attright_sm = smooth_with_gaussian(right_input_attendingright_t, sigma=sigma)\n",
    "    attlay_attright_sm = smooth_with_gaussian(attention_layer_attendingright_t, sigma=sigma)\n",
    "\n",
    "    #print shapes of each\n",
    "    print(\"left_in_attleft_sm\", left_in_attleft_sm.shape)\n",
    "    print(\"right_in_attleft_sm\", right_in_attleft_sm.shape)\n",
    "    print(\"attlay_attleft_sm\", attlay_attleft_sm.shape)\n",
    "\n",
    "    print(\"=== Initial Smoothed Data ===\")\n",
    "    print(\"left_in_attleft_sm shape:\", left_in_attleft_sm.shape)\n",
    "    print(\"right_in_attleft_sm shape:\", right_in_attleft_sm.shape)\n",
    "    print(\"attlay_attleft_sm shape:\", attlay_attleft_sm.shape)\n",
    "\n",
    "    print(\"\\nSnippet from left_in_attleft_sm (Trial 0, first 3 timepoints, first 5 neurons):\")\n",
    "    print(left_in_attleft_sm[0, :, :5])\n",
    "\n",
    "    num_trials_left, num_samples, num_neurons_left = left_input_attendingleft_t.shape\n",
    "    num_trials_right = left_input_attendingright_t.shape[0]\n",
    "    num_neurons_attention = 80\n",
    "\n",
    "            \n",
    "    for j in range(0, num_trials_left):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attleft_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attleft_sm[j, :, i] /= count_right\n",
    "\n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingleft_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attleft_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(0, num_trials_right):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attright_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attright_sm[j, :, i] /= count_right    \n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingright_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attright_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    left_in_attleft_sum = np.sum(left_in_attleft_sm, axis=2)\n",
    "    right_in_attleft_sum = np.sum(right_in_attleft_sm, axis=2)\n",
    "    attlay_attleft_sum = np.sum(attlay_attleft_sm, axis=2)\n",
    "\n",
    "    left_in_attright_sum = np.sum(left_in_attright_sm, axis=2)\n",
    "    right_in_attright_sum = np.sum(right_in_attright_sm, axis=2)\n",
    "    attlay_attright_sum = np.sum(attlay_attright_sm, axis=2)\n",
    "\n",
    "    print(\"\\n=== After Summing Over Neurons ===\")\n",
    "    print(\"left_in_attleft_sum shape:\", left_in_attleft_sum.shape)\n",
    "    print(\"right_in_attleft_sum shape:\", right_in_attleft_sum.shape)\n",
    "    print(\"attlay_attleft_sum shape:\", attlay_attleft_sum.shape)\n",
    "\n",
    "    # Print a snippet from left_in_attleft_sum:\n",
    "    # (Trial 0, first 10 timepoints)\n",
    "    print(\"\\nSnippet from left_in_attleft_sum (Trial 0, first 10 timepoints):\")\n",
    "    print(left_in_attleft_sum[0, :10])\n",
    "    print(\"\\nSnippet from left_in_attleft_sum (Trial 1, first 10 timepoints):\")\n",
    "    print(left_in_attleft_sum[1, :10])\n",
    "    print(\"\\nSnippet from left_in_attleft_sum (Trial 2, first 10 timepoints):\")\n",
    "    print(left_in_attleft_sum[2, :10])\n",
    "    print(\"\\nSnippet from left_in_attleft_sum (Trial 3, first 10 timepoints):\")\n",
    "    print(left_in_attleft_sum[3, :10])\n",
    "    print(\"\\nSnippet from left_in_attleft_sum (Trial 4, first 10 timepoints):\")\n",
    "    print(left_in_attleft_sum[4, :10])\n",
    "\n",
    "\n",
    "    # #plotting trials 1 to 5\n",
    "    # t = np.arange(100, 350)\n",
    "    # trial_index = 5\n",
    "    # plt.plot(t, left_in_attleft_sum[trial_index], label='Left Input', color='r')\n",
    "    # plt.plot(t, right_in_attleft_sum[trial_index], label='Right Input', color='b')\n",
    "    # plt.plot(t, attlay_attleft_sum[trial_index], label='Attention Layer', color='g')\n",
    "    # plt.title('Attention Left: Trial 4')\n",
    "    # plt.xlabel('Time (ms)')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    n_samples = left_in_attleft_sum.shape[1]   ##change this for correct time \n",
    "    print(\"n_samples:\", n_samples)\n",
    "\n",
    "    dt = 0.002\n",
    "    sfreq = 1 / dt  # Sampling frequency\n",
    "\n",
    "    ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "    ch_types = ['eeg', 'eeg', 'eeg']\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    print(\"Left shape:\", left_in_attleft_sum.shape)\n",
    "    print(\"Right shape:\", right_in_attleft_sum.shape)\n",
    "    print(\"Attention shape:\", attlay_attleft_sum.shape)\n",
    "\n",
    "\n",
    "    #reshaping data for attention left\n",
    "    raw_data_left = np.concatenate([\n",
    "        left_in_attleft_sum, \n",
    "        right_in_attleft_sum, \n",
    "        attlay_attleft_sum\n",
    "    ], axis=0)  # Concatenate along time axis\n",
    "\n",
    "    print(\"\\n=== After Concatenation ===\")\n",
    "    print(\"After concatenation, shape:\", raw_data_left.shape)\n",
    "    # Expecting shape: (495 + 495 + 495 = 1485, 250)\n",
    "    #Print a snippet from the concatenated data:\n",
    "    # (First 5 rows, first 10 timepoints)\n",
    "\n",
    "\n",
    "    # Reshape into (n_channels, n_samples)\n",
    "    raw_data_left = raw_data_left.reshape(3, -1)\n",
    "    print('raw data left shape:', raw_data_left.shape)\n",
    "    print(\"\\nSnippet from raw_data_concat (first 5 rows, first 10 timepoints):\")\n",
    "    print(raw_data_left[:5, :10])\n",
    "\n",
    "\n",
    "    raw_left = mne.io.RawArray(raw_data_left, info)\n",
    "\n",
    "    print(\"\\n=== Visual Inspection of Each Channel ===\")\n",
    "    print(\"Channel 0 (Left Input) - first 20 samples:\")\n",
    "    print(raw_data_left[0, :20])\n",
    "    print(\"\\nChannel 1 (Right Input) - first 20 samples:\")\n",
    "    print(raw_data_left[1, :20])\n",
    "    print(\"\\nChannel 2 (Attention Layer) - first 20 samples:\")\n",
    "    print(raw_data_left[2, :20])\n",
    "\n",
    "    #reshaping data for attention right\n",
    "    raw_data_right = np.concatenate([\n",
    "        left_in_attright_sum, \n",
    "        right_in_attright_sum, \n",
    "        attlay_attright_sum\n",
    "    ], axis=0)  # Concatenate along time axis\n",
    "\n",
    "    # Reshape into (n_channels, n_samples)\n",
    "    raw_data_right = raw_data_right.reshape(3, -1)\n",
    "    print('raw data right shape:', raw_data_right.shape)\n",
    "\n",
    "    raw_right = mne.io.RawArray(raw_data_right, info)\n",
    "\n",
    "\n",
    "    events_left = np.array([[i * n_samples, 0, 1] for i in range(len(attend_left_not_omitted))])\n",
    "    events_right = np.array([[i * n_samples, 0, 1] for i in range(len(attend_right_not_omitted))])\n",
    "\n",
    "    epochs_left = mne.Epochs(raw_left, events_left, event_id={'Trial': 1}, tmin = 0.1, tmax = 0.35,  baseline=None, preload=True)\n",
    "    epochs_right = mne.Epochs(raw_right, events_right, event_id={'Trial': 1}, tmin = 0.1, tmax = 0.35, baseline=None, preload=True)\n",
    "    print(epochs_right.times)\n",
    "\n",
    "\n",
    "    #wSMI for each condition\n",
    "    kernel = 3\n",
    "    taus = [8, 16, 32, 64]  # in ms\n",
    "    wsmi_results = {'left': {}, 'right': {}}\n",
    "\n",
    "\n",
    "    print(f\"tau_samples for {taus}: {[int(t / (1000 / sfreq)) for t in taus]}\")\n",
    "\n",
    "    for tau_ms in taus:\n",
    "        tau_samples = int(tau_ms / (1000 / sfreq))  # Convert ms to samples\n",
    "        \n",
    "\n",
    "        #wSMI for attention left\n",
    "        wsmi_left, _, _, _ = epochs_compute_wsmi(\n",
    "            epochs_left, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "        )\n",
    "        wsmi_results['left'][tau_ms] = wsmi_left\n",
    "        \n",
    "\n",
    "        #wSMI for attention right\n",
    "        wsmi_right, _, _, _ = epochs_compute_wsmi(\n",
    "            epochs_right, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "        )\n",
    "        wsmi_results['right'][tau_ms] = wsmi_right\n",
    "\n",
    "\n",
    "\n",
    "    wsmi_left_input_left = []  #wSMI for left input vs attention layer (attention left)\n",
    "    wsmi_right_input_left = []  #wSMI for right input vs attention layer (attention left)\n",
    "    wsmi_left_input_right = []  #wSMI for left input vs attention layer (attention right)\n",
    "    wsmi_right_input_right = []  #wSMI for right input vs attention layer (attention right)\n",
    "\n",
    "    #average wSMI for each Ï„ for each condition\n",
    "    for tau in taus:\n",
    "        # For attention left\n",
    "        wsmi_left_input_left.append(np.mean(wsmi_results['left'][tau][0, 2, :]))  # Left input vs attention layer\n",
    "        wsmi_right_input_left.append(np.mean(wsmi_results['left'][tau][1, 2, :]))  # Right input vs attention layer\n",
    "\n",
    "        # For attention right\n",
    "        wsmi_left_input_right.append(np.mean(wsmi_results['right'][tau][0, 2, :]))  # Left input vs attention layer\n",
    "        wsmi_right_input_right.append(np.mean(wsmi_results['right'][tau][1, 2, :]))  # Right input vs attention layer\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "    #left subplot\n",
    "    axs[0].scatter(taus, wsmi_left_input_left, label=\"Left Input vs Attention Layer\", marker=\"x\",color = 'r', s=100)\n",
    "    axs[0].scatter(taus, wsmi_right_input_left, label=\"Right Input vs Attention Layer\", marker=\"x\",color = 'k', s=100)\n",
    "    axs[0].set_title(\"Attention Left\", fontsize=14)\n",
    "    axs[0].set_xlabel(\"Ï„ (ms)\", fontsize=12)\n",
    "    axs[0].set_ylabel(\"Average wSMI\", fontsize=12)\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(False)\n",
    "\n",
    "    #right subplot\n",
    "    axs[1].scatter(taus, wsmi_left_input_right, label=\"Left Input vs Attention Layer\", marker=\"x\", color = 'r', s=100)\n",
    "    axs[1].scatter(taus, wsmi_right_input_right, label=\"Right Input vs Attention Layer\", marker=\"x\",color = 'k', s=100)\n",
    "    axs[1].set_title(\"Attention Right\", fontsize=14)\n",
    "    axs[1].set_xlabel(\"Ï„ (ms)\", fontsize=12)\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    for tau_to_check in taus:\n",
    "\n",
    "        # Extract the wSMI matrix for the first trial (attention left)\n",
    "        wsmi_first_trial_left = wsmi_results['left'][tau_to_check][:, :, 0]  # 0 corresponds to the first trial\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"wSMI matrix for the first trial (attention left) at tau={tau_to_check} ms:\\n\", wsmi_first_trial_left)\n",
    "\n",
    "\n",
    "\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    attleft_pearson_left = []\n",
    "    attleft_pearson_right = []\n",
    "    attright_pearson_left = []\n",
    "    attright_pearson_right = []\n",
    "\n",
    "\n",
    "    for i in range(len(attend_left_not_omitted)):\n",
    "        corr_left, _ = pearsonr(left_in_attleft_sum[i], attlay_attleft_sum[i])\n",
    "        attleft_pearson_left.append(corr_left)\n",
    "        corr_right, _ = pearsonr(right_in_attleft_sum[i], attlay_attleft_sum[i])\n",
    "        attleft_pearson_right.append(corr_right)\n",
    "\n",
    "    for i in range(len(attend_right_not_omitted)):\n",
    "        corr_left, _ = pearsonr(left_in_attright_sum[i], attlay_attright_sum[i])\n",
    "        attright_pearson_left.append(corr_left)\n",
    "        corr_right, _ = pearsonr(right_in_attright_sum[i], attlay_attright_sum[i])\n",
    "        attright_pearson_right.append(corr_right)\n",
    " \n",
    "\n",
    "    mean_corr_left_attleft = np.mean(attleft_pearson_left)\n",
    "    mean_corr_right_attleft = np.mean(attleft_pearson_right)\n",
    "    mean_corr_left_attright = np.mean(attright_pearson_left)\n",
    "    mean_corr_right_attright = np.mean(attright_pearson_right)\n",
    "\n",
    "    print(\"mean correlation for left_attleft\", mean_corr_left_attleft)\n",
    "    print(\"mean correlation for right_attleft\", mean_corr_right_attleft)\n",
    "    print(\"mean correlation for left_attright\", mean_corr_left_attright)\n",
    "    print(\"mean correlation for right_attright\", mean_corr_right_attright)\n",
    "\n",
    "\n",
    "\n",
    "    # Instead of x_axis = ['left', 'right'], use numeric x positions:\n",
    "    x = [0, 1]\n",
    "\n",
    "    # Create your figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot using the numeric x positions\n",
    "    axs[0].scatter(x, [mean_corr_left_attleft, mean_corr_right_attleft],\n",
    "                label=\"Attention Left\", color='k', marker='x', s=100)\n",
    "    axs[1].scatter(x, [mean_corr_left_attright, mean_corr_right_attright],\n",
    "                label=\"Attention Right\", color='k', marker='x', s=100)\n",
    "\n",
    "    # Set x-tick positions and labels for each subplot\n",
    "    for ax in axs:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['left', 'right'])\n",
    "        # Optionally, adjust x-limits to make the points closer to the center:\n",
    "        ax.set_xlim(-0.5, 1.5)\n",
    "\n",
    "    axs[0].set_title(\"Attention Left\", fontsize=14)\n",
    "    axs[1].set_title(\"Attention Right\", fontsize=14)\n",
    "    axs[0].set_ylabel(\"Mean Pearson Correlation\", fontsize=12)\n",
    "    axs[1].set_ylabel(\"Mean Pearson Correlation\", fontsize=12)\n",
    "\n",
    "    axs[0].grid(False)\n",
    "    axs[1].grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf9aba-ec67-401e-9da8-428ee26115d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LFP data - Coherence\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from coherence import field_field_coherence\n",
    "np.set_printoptions(threshold=100)\n",
    "\n",
    "i_values = [1, 2, 3, 4, 8, 14, 15, 20, 23]\n",
    "for file_number in i_values:\n",
    "    # Load data\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    attention_labels = data['label_attend'][0]\n",
    "    label_left = data['label_left'][0]\n",
    "    label_right = data['label_right'][0]\n",
    "    attend_01 = data['attend'][0]\n",
    "    omitted = data[\"omit\"][0]\n",
    "\n",
    "    # # Subset indices based on omitted and attention conditions:\n",
    "    # left_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 0))[0]\n",
    "    # right_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 1))[0]\n",
    "\n",
    "    # Subset indices based on omitted and attention conditions:\n",
    "    left_indices = np.where((omitted == 0) & (attend_01 == 0))[0]\n",
    "    right_indices = np.where((omitted == 0) & (attend_01 == 1))[0]\n",
    "\n",
    "    # Get continuous LFP signals\n",
    "    left_input_LFP = data['LFP'][0][0]   # Left input\n",
    "    right_input_LFP = data['LFP'][0][1]  # Right input\n",
    "    attention_LFP = data['LFP_rec'][0][2]  # Attention layer\n",
    "\n",
    "    # Subset the LFP arrays for each condition (select trials & relevant time indices)\n",
    "    left_input_LFP_om_left = left_input_LFP[left_indices][:, 100:350]\n",
    "    right_input_LFP_om_left = right_input_LFP[left_indices][:, 100:350]\n",
    "    attention_LFP_om_left = attention_LFP[left_indices][:, 100:350]\n",
    "\n",
    "    left_input_LFP_om_right = left_input_LFP[right_indices][:, 100:350]\n",
    "    right_input_LFP_om_right = right_input_LFP[right_indices][:, 100:350]\n",
    "    attention_LFP_om_right = attention_LFP[right_indices][:, 100:350]\n",
    "\n",
    "    # Set dt and other parameters\n",
    "    dt = 0.002  # seconds\n",
    "    print(f\"File {i}: Attention left LFP shape:\", attention_LFP_om_left.shape)\n",
    "    print(f\"File {i}: Attention right LFP shape:\", attention_LFP_om_right.shape)\n",
    "\n",
    "    # --- Computing Field-Field Coherence ---\n",
    "    #for attention left condition:\n",
    "    left_in_coh_leftatt, freq = field_field_coherence(\n",
    "        left_input_LFP_om_left,\n",
    "        attention_LFP_om_left,\n",
    "        dt\n",
    "    )\n",
    "    right_in_coh_leftatt, freq = field_field_coherence(\n",
    "        right_input_LFP_om_left,\n",
    "        attention_LFP_om_left,\n",
    "        dt\n",
    "    )\n",
    "\n",
    "    #for attention right condition:\n",
    "    left_in_coh_rightatt, freq = field_field_coherence(\n",
    "        left_input_LFP_om_right,\n",
    "        attention_LFP_om_right,\n",
    "        dt\n",
    "    )\n",
    "    right_in_coh_rightatt, freq = field_field_coherence(\n",
    "        right_input_LFP_om_right,\n",
    "        attention_LFP_om_right,\n",
    "        dt\n",
    "    )\n",
    "\n",
    "    # Plotting the coherence results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for attention left condition\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(freq, left_in_coh_leftatt, label='Left Input - Attention Layer', color = 'r')\n",
    "    plt.plot(freq, right_in_coh_leftatt, label='Right Input - Attention Layer', color = 'k')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Coherence')\n",
    "    plt.title(f'Attention Left Condition - Dataset {file_number} - LFP')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for attention right condition\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(freq, left_in_coh_rightatt, label='Left Input - Attention Layer', color = 'r')\n",
    "    plt.plot(freq, right_in_coh_rightatt, label='Right Input - Attention Layer', color = 'k')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Coherence')\n",
    "    plt.title(f'Attention Right Condition - Dataset {file_number} - LFP')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33240805-77fa-4a3d-826e-23c8a4e5a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spiking data - Coherence\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from coherence import field_field_coherence\n",
    "\n",
    "\n",
    "i_values = [1, 2, 3, 4, 8, 14, 15, 20, 23]\n",
    "for file_number in i_values:\n",
    "    # Load data\n",
    "\n",
    "    file_path = f'C:/Users/joshu/PartIIIProject/RSNNdale_attention_{file_number}_attention_test'\n",
    "    data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "    left_input_SP = data['SP'][0][0] \n",
    "    right_input_SP = data['SP'][0][1]\n",
    "    attention_SP = data['SP'][0][2]\n",
    "    label_left = data['label_left'][0]\n",
    "    label_right = data['label_right'][0]\n",
    "    # left_input_SP (2032, 500, 160)\n",
    "    # right_input_SP (2032, 500, 160)\n",
    "    # attention_SP (2032, 500, 80)\n",
    "    \n",
    "\n",
    "    # attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "    # attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0) & (label_left != label_right))[0]\n",
    "\n",
    "    attend_left_not_omitted = np.where((data[\"attend\"][0] == 0) & (data[\"omit\"][0] == 0))[0]\n",
    "    attend_right_not_omitted = np.where((data[\"attend\"][0] == 1) & (data[\"omit\"][0] == 0))[0]\n",
    "\n",
    "    left_input_attendingleft_t = left_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    right_input_attendingleft_t = right_input_SP[attend_left_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingleft_t = attention_SP[attend_left_not_omitted, 100:350, :]\n",
    "\n",
    "    left_input_attendingright_t = left_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    right_input_attendingright_t = right_input_SP[attend_right_not_omitted, 100:350, :]\n",
    "    attention_layer_attendingright_t = attention_SP[attend_right_not_omitted, 100:350, :]\n",
    "\n",
    "    #eft_input_attendingleft_t (468, 250, 160) (80 for attention)\n",
    "    #left_input_attendingright_t (536, 250, 160) (80 for attention)\n",
    "\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "    def smooth_with_gaussian(data, sigma=3):\n",
    "        return gaussian_filter1d(data, sigma=sigma, axis=1) \n",
    "\n",
    "    sigma = 2\n",
    "\n",
    "    left_in_attleft_sm = smooth_with_gaussian(left_input_attendingleft_t, sigma=sigma) \n",
    "    right_in_attleft_sm = smooth_with_gaussian(right_input_attendingleft_t, sigma=sigma) \n",
    "    attlay_attleft_sm = smooth_with_gaussian(attention_layer_attendingleft_t, sigma=sigma) \n",
    "\n",
    "    left_in_attright_sm = smooth_with_gaussian(left_input_attendingright_t, sigma=sigma) \n",
    "    right_in_attright_sm = smooth_with_gaussian(right_input_attendingright_t, sigma=sigma)\n",
    "    attlay_attright_sm = smooth_with_gaussian(attention_layer_attendingright_t, sigma=sigma)\n",
    "\n",
    "\n",
    "    num_trials_left, num_samples, num_neurons_left = left_input_attendingleft_t.shape\n",
    "    num_trials_right = left_input_attendingright_t.shape[0]\n",
    "    num_neurons_attention = 80\n",
    "\n",
    "            \n",
    "    for j in range(0, num_trials_left):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attleft_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingleft_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attleft_sm[j, :, i] /= count_right\n",
    "\n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingleft_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attleft_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(0, num_trials_right):\n",
    "        for i in range(0, num_neurons_left):\n",
    "            count_left = np.count_nonzero(left_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_left > 0:\n",
    "                left_in_attright_sm[j, :, i] /= count_left\n",
    "            count_right = np.count_nonzero(right_input_attendingright_t[j, :, i] == 1)\n",
    "            if count_right > 0:\n",
    "                right_in_attright_sm[j, :, i] /= count_right    \n",
    "\n",
    "        for i in range(0, num_neurons_attention):\n",
    "            count_attention = np.count_nonzero(attention_layer_attendingright_t[j, :, i] == 1)\n",
    "            if count_attention > 0:\n",
    "                attlay_attright_sm[j, :, i] /= count_attention\n",
    "\n",
    "\n",
    "    left_in_attleft_sum = np.sum(left_in_attleft_sm, axis=2)\n",
    "    right_in_attleft_sum = np.sum(right_in_attleft_sm, axis=2)\n",
    "    attlay_attleft_sum = np.sum(attlay_attleft_sm, axis=2)\n",
    "\n",
    "    left_in_attright_sum = np.sum(left_in_attright_sm, axis=2)\n",
    "    right_in_attright_sum = np.sum(right_in_attright_sm, axis=2)\n",
    "    attlay_attright_sum = np.sum(attlay_attright_sm, axis=2)\n",
    "\n",
    "    dt = 0.002\n",
    "\n",
    "    # --- Computing Field-Field Coherence --\n",
    "\n",
    "    #for attention left condition:\n",
    "    left_in_coh_leftatt, freq = field_field_coherence(\n",
    "        left_in_attleft_sum,\n",
    "        attlay_attleft_sum,\n",
    "        dt\n",
    "    )\n",
    "    right_in_coh_leftatt, freq = field_field_coherence(\n",
    "        right_in_attleft_sum,\n",
    "        attlay_attleft_sum,\n",
    "        dt\n",
    "    )\n",
    "\n",
    "    #for attention right condition:\n",
    "    left_in_coh_rightatt, freq = field_field_coherence(\n",
    "        left_in_attright_sum,\n",
    "        attlay_attright_sum,\n",
    "        dt\n",
    "    )\n",
    "    right_in_coh_rightatt, freq = field_field_coherence(\n",
    "        right_in_attright_sum,\n",
    "        attlay_attright_sum,\n",
    "        dt\n",
    "    )\n",
    "\n",
    "    #plotting the coherence results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    #plot for attention left condition\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(freq, left_in_coh_leftatt, label='Left Input - Attention Layer', color = 'r')\n",
    "    plt.plot(freq, right_in_coh_leftatt, label='Right Input - Attention Layer', color = 'k')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Coherence')\n",
    "    plt.title(f'Attention Left Condition - Dataset {file_number} - SP')\n",
    "    plt.legend()\n",
    "\n",
    "    #plot for attention right condition\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(freq, left_in_coh_rightatt, label='Left Input - Attention Layer', color = 'r')\n",
    "    plt.plot(freq, right_in_coh_rightatt, label='Right Input - Attention Layer', color = 'k')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Coherence')\n",
    "    plt.title(f'Attention Right Condition - Dataset {file_number} - SP')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

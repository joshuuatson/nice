{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36366f0f-48ba-45df-9281-704a49e5bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\externals\\tempita\\__init__.py:35: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]\n",
      "label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]\n",
      "label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]\n",
      "attend01 [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "class_different_indices [   0    1    4 ... 2024 2029 2031]\n",
      "shape of class_different_indices (1004,)\n",
      "shape of left_indices (468,)\n",
      "shape of right_indices (536,)\n",
      "n_samples 500\n",
      "n_trials 468\n",
      "raw data left shape: (3, 234000)\n",
      "raw data left, attending left, trial 0: [ 0.          8.30495834  6.72716999 ... 75.45306396 79.49226379\n",
      " 71.67674255]\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=234000\n",
      "    Range : 0 ... 233999 =      0.000 ...   467.998 secs\n",
      "Ready.\n",
      "raw data right shape: (3, 268000)\n",
      "raw data right, attending right, first right attending trial: [  0.          16.3247776   16.00920868 ... 126.37789154 154.7988739\n",
      " 140.4855957 ]\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=268000\n",
      "    Range : 0 ... 267999 =      0.000 ...   535.998 secs\n",
      "Ready.\n",
      "events_left [[   0    0    1]\n",
      " [ 500    0    1]\n",
      " [1000    0    1]\n",
      " [1500    0    1]]\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "468 matching events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\epochs.py:406: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  selected = np.where(np.in1d(self.events[:, 2], values))[0]\n",
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\epochs.py:431: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  sub = np.where(np.in1d(selection, self.selection))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 468 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "536 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 536 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "tau_samples for 8: 4\n",
      "Cannot autodetect number of jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\epochs.py:406: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  selected = np.where(np.in1d(self.events[:, 2], values))[0]\n",
      "c:\\Users\\joshu\\nice\\.venv\\Lib\\site-packages\\mne\\epochs.py:431: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  sub = np.where(np.in1d(selection, self.selection))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing CSD\n",
      "Filtering  at 41.67 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 41.67 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "tau_samples for 16: 8\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 20.83 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 20.83 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "tau_samples for 32: 16\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 10.42 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 10.42 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n",
      "tau_samples for 64: 32\n",
      "Cannot autodetect number of jobs\n",
      "Bypassing CSD\n",
      "Filtering  at 5.21 Hz\n",
      "Performing symbolic transformation\n",
      "Running wsmi with python...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nice.algorithms.connectivity import epochs_compute_wsmi\n",
    "np.set_printoptions(threshold=100)  # Default threshold\n",
    "\n",
    "#load data\n",
    "file_path = 'C:/Users/joshu/PartIIIProject/RSNNdale_attention_1_attention_test'\n",
    "data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "attention_labels = data['label_attend'][0]\n",
    "print(\"attend\", attention_labels[:10])\n",
    "label_left = data['label_left'][0]\n",
    "print(\"label_left\", label_left[:10])\n",
    "label_right = data['label_right'][0]\n",
    "print(\"label_right\", label_right[:10])\n",
    "attend_01 = data['attend'][0]\n",
    "print (\"attend01\", attend_01[:10])\n",
    "\n",
    "\n",
    "#not filtered for omitted trials \n",
    "left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right \n",
    "right_input_LFP = data['LFP'][0][1]  # Right input\n",
    "attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention \n",
    "\n",
    "omitted = data[\"omit\"][0]\n",
    "# print(\"omitted\", omitted[:10])\n",
    "\n",
    "#trials where label_left and label_right differ, and trial isn't omitted\n",
    "class_different_indices = np.where((label_left != label_right) & (omitted == 0))[0]\n",
    "\n",
    "\n",
    "#subset further based on attention\n",
    "left_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 0))[0]\n",
    "right_indices = np.where((label_left != label_right) & (omitted == 0) & (attend_01 == 1))[0]\n",
    "\n",
    "print(\"class_different_indices\", class_different_indices)\n",
    "print(\"shape of class_different_indices\", class_different_indices.shape)\n",
    "print(\"shape of left_indices\", left_indices.shape)\n",
    "print(\"shape of right_indices\", right_indices.shape)\n",
    "\n",
    "left_input_LFP_om_left = left_input_LFP[left_indices]\n",
    "right_input_LFP_om_left = right_input_LFP[left_indices]\n",
    "\n",
    "left_input_LFP_om_right = left_input_LFP[right_indices]\n",
    "right_input_LFP_om_right = right_input_LFP[right_indices]\n",
    "\n",
    "attention_LFP_om_left = attention_LFP[left_indices]\n",
    "attention_LFP_om_right = attention_LFP[right_indices]\n",
    "\n",
    "# attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]\n",
    "# label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]\n",
    "# label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]\n",
    "# omitted [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
    "\n",
    "\n",
    "n_times = left_input_LFP.shape[1] ##=500\n",
    "n_trials = left_input_LFP_om_left.shape[0]\n",
    "print(\"n_samples\", n_times)\n",
    "print(\"n_trials\", n_trials)\n",
    "\n",
    "dt = 0.002\n",
    "sfreq = 1 / dt\n",
    "\n",
    "\n",
    "ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "ch_types = ['eeg', 'eeg', 'eeg']\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "\n",
    "#reshaping data for attention left\n",
    "raw_data_left = np.concatenate([\n",
    "    left_input_LFP_om_left, \n",
    "    right_input_LFP_om_left, \n",
    "    attention_LFP_om_left\n",
    "], axis=0)  # Concatenate along time axis\n",
    "\n",
    "# Reshape into (n_channels, n_samples)\n",
    "raw_data_left = raw_data_left.reshape(3, -1)  # Now (3, 468*500) = (3, 234000)\n",
    "print('raw data left shape:', raw_data_left.shape)  # (3, 234000)\n",
    "print('raw data left, attending left, trial 0:', raw_data_left[0, :n_times])\n",
    "#raw data left, attending left, trial 0: [ 0.          8.30495834  6.72716999 ... 75.45306396 79.49226379, 71.67674255]\n",
    "\n",
    "\n",
    "raw_left = mne.io.RawArray(raw_data_left, info)\n",
    "\n",
    "\n",
    "\n",
    "#reshaping date for attention right \n",
    "raw_data_right = np.concatenate([\n",
    "    left_input_LFP_om_right,\n",
    "    right_input_LFP_om_right,\n",
    "    attention_LFP_om_right\n",
    "], axis=0)\n",
    "\n",
    "raw_data_right = raw_data_right.reshape(3, -1)\n",
    "print('raw data right shape:', raw_data_right.shape)\n",
    "print('raw data right, attending right, first right attending trial:', raw_data_right[1, 2*n_times:3*n_times])\n",
    "#raw data right, attending right, first right attending trial: [  0.          16.3247776   16.00920868 ... 126.37789154 154.798873,  140.4855957 ]\n",
    "#this is good, it is the same as in the single trial case, and seems to be stacking correctly\n",
    "\n",
    "\n",
    "raw_right = mne.io.RawArray(raw_data_right, info)\n",
    "\n",
    "#Creating RawArray with float64 data, n_channels=3, n_times=268000\n",
    "#    Range : 0 ... 267999 =      0.000 ...   535.998 secs     why this time? seems to be out by 0.002 seconds of what would be expected\n",
    "\n",
    "#defininf event objects, arrays like [0,0,1], [500, 0, 1], [1000, 0, 1] etc\n",
    "events_left = np.array([[i * n_times, 0, 1] for i in range(len(left_input_LFP_om_left))])\n",
    "events_right = np.array([[i * n_times, 0, 1] for i in range(len(right_input_LFP_om_right))])\n",
    "\n",
    "\n",
    "print(\"events_left\", events_left[:4])\n",
    "\n",
    "epochs_left = mne.Epochs(raw_left, events_left, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "epochs_right = mne.Epochs(raw_right, events_right, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "\n",
    "kernel = 3\n",
    "taus = [8, 16, 32, 64]  # in ms\n",
    "wsmi_results = {'left': {}, 'right': {}}\n",
    "\n",
    "for tau in taus:\n",
    "    tau_samples = int(tau / (1000 / sfreq))\n",
    "    print(f\"tau_samples for {tau}: {tau_samples}\")\n",
    "    \n",
    "    wsmi_left, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_left, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "    wsmi_results['left'][tau] = wsmi_left\n",
    "    #this containts the data for wsmi at a given tau given attending left. \n",
    "\n",
    "    wsmi_right, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_right, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "    wsmi_results['right'][tau] = wsmi_right\n",
    "\n",
    "\n",
    "\n",
    "print('wsmi_results.shape', wsmi_results['left'][8].shape)\n",
    "#wsmi_results.shape (3, 3, 468), so get a 3x3 for each trial. note that values for performing a single trial are different to \n",
    "#extracting the wsmi value of the first trial from wsmi_results. unsure why. \n",
    "\n",
    "for tau_to_check in taus:\n",
    "\n",
    "    # Extract the wSMI matrix for the first trial (attention left)\n",
    "    wsmi_first_trial_left = wsmi_results['left'][tau_to_check][:, :, 0]  # 0 corresponds to the first trial\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"wSMI matrix for the first trial (attention left) at tau={tau_to_check} ms:\\n\", wsmi_first_trial_left)\n",
    "\n",
    "\n",
    "\n",
    "# wSMI matrix for the first trial (attention left) at tau=8 ms:\n",
    "#  [[0.         0.00228504 0.02923702]\n",
    "#  [0.         0.         0.00223716]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wSMI matrix for the first trial (attention left) at tau=16 ms:\n",
    "#  [[0.         0.01912681 0.03944688]\n",
    "#  [0.         0.         0.00618852]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wSMI matrix for the first trial (attention left) at tau=32 ms:\n",
    "#  [[0.         0.12345667 0.02594063]\n",
    "#  [0.         0.         0.00655333]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wSMI matrix for the first trial (attention left) at tau=64 ms:\n",
    "#  [[0.         0.14327575 0.07129394]\n",
    "#  [0.         0.         0.08184199]\n",
    "#  [0.         0.         0.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e052170-a899-4444-8c04-61585ea5989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nice.algorithms.connectivity import epochs_compute_wsmi\n",
    "np.set_printoptions(threshold=100)  #default threshold\n",
    "\n",
    "#load data\n",
    "file_path = 'C:/Users/joshu/PartIIIProject/RSNNdale_attention_1_attention_test'\n",
    "data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "attention_labels = data['label_attend'][0]\n",
    "label_left = data['label_left'][0]\n",
    "label_right = data['label_right'][0]\n",
    "attend_01 = data['attend'][0]\n",
    "\n",
    "\n",
    "#not filtered for omitted trials \n",
    "left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right \n",
    "right_input_LFP = data['LFP'][0][1]  # Right input\n",
    "attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention \n",
    "omitted = data[\"omit\"][0]\n",
    "\n",
    "\n",
    "# attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]\n",
    "# label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]\n",
    "# label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]\n",
    "#attend01 [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
    "#omitted [0. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
    "\n",
    "\n",
    "trial_idx = 0\n",
    "left_input_trial = left_input_LFP[trial_idx]\n",
    "right_input_trial= right_input_LFP[trial_idx]\n",
    "attention_trial = attention_LFP[trial_idx]\n",
    "\n",
    "print(\"left_input_trial\", left_input_trial[0:20])\n",
    "print(\"right_input_trial\", right_input_trial[0:20])\n",
    "print(\"attention_trial\", attention_trial[0:20])\n",
    "\n",
    "\n",
    "raw_data_raw = np.stack([left_input_trial, right_input_trial, attention_trial])\n",
    "print(raw_data_raw.shape)\n",
    "print(raw_data_raw)\n",
    "print('right, attending right, trial 14:', raw_data_raw[1])\n",
    "#right, attending right, trial 14: [   0.           16.3247776    16.00920868   20.1116848...\n",
    "\n",
    "n_times = raw_data_raw.shape[1] ##=500\n",
    "print(\"n_samples\", n_times)\n",
    "\n",
    "dt = 0.002\n",
    "sfreq = 1 / dt\n",
    "ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "ch_types = ['eeg', 'eeg', 'eeg']\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "\n",
    "raw_data = mne.io.RawArray(raw_data_raw, info)\n",
    "\n",
    "events = np.array([\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "\n",
    "epochs_raw = mne.Epochs(raw_data, events, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "\n",
    "print(\"Raw data shape:\", raw_data.get_data().shape)\n",
    "print(\"epochs_raw shape:\", epochs_raw.get_data().shape)\n",
    "print(\"Events array:\", events)\n",
    "print(\"Number of epochs:\", len(epochs_raw))\n",
    "\n",
    "\n",
    "kernel = 3\n",
    "taus = [8, 16, 32, 64]  # in ms\n",
    "#making wsmi results dictionary to store raw, normalised, and smoothed data\n",
    "wsmi_results = {}\n",
    "\n",
    "for tau in taus:\n",
    "    tau_samples = int(tau / (1000 / sfreq))\n",
    "    print(f\"tau_samples for {tau}: {tau_samples}\")\n",
    "    \n",
    "    wsmi, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_raw, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "\n",
    "    wsmi_results[tau] = wsmi\n",
    "\n",
    "\n",
    "for tau in taus:\n",
    "\n",
    "    print(\"wsmi results raw\", wsmi_results[tau][:, :, 0])\n",
    "\n",
    "# wsmi results raw [[0.         0.00236065 0.02781281]\n",
    "#  [0.         0.         0.00095507]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wsmi results raw [[0.         0.01833334 0.02831222]\n",
    "#  [0.         0.         0.00670613]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wsmi results raw [[0.         0.11334197 0.00812583]\n",
    "#  [0.         0.         0.01633531]\n",
    "#  [0.         0.         0.        ]]\n",
    "# wsmi results raw [[0.         0.12664354 0.10996675]\n",
    "#  [0.         0.         0.10764085]\n",
    "#  [0.         0.         0.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a855364-abae-4169-8242-910e892b6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nice.algorithms.connectivity import epochs_compute_wsmi\n",
    "np.set_printoptions(threshold=900)  #default threshold\n",
    "\n",
    "#load data\n",
    "file_path = 'C:/Users/joshu/PartIIIProject/RSNNdale_attention_1_attention_test'\n",
    "data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "attention_labels = data['label_attend'][0]\n",
    "print(\"attend\", attention_labels[:10])\n",
    "label_left = data['label_left'][0]\n",
    "print(\"label_left\", label_left[:10])\n",
    "label_right = data['label_right'][0]\n",
    "print(\"label_right\", label_right[:10])\n",
    "attend_01 = data['attend'][0]\n",
    "print (\"attend01\", attend_01[:10])\n",
    "\n",
    "\n",
    "#not filtered for omitted trials \n",
    "left_input_LFP = data['LFP'][0][0]  # Left input  [0,1] means left, Right \n",
    "right_input_LFP = data['LFP'][0][1]  # Right input\n",
    "attention_LFP = data['LFP_rec'][0][2]  # Attention layer  [2] means attention \n",
    "\n",
    "omitted = data[\"omit\"][0]\n",
    "print(\"omitted\", omitted[:10])\n",
    "\n",
    "# attend [11. 14. 18. 15.  2.  5. 12. 16.  2.  0.]\n",
    "# label_left [11. 14.  6. 18.  2.  5.  6. 10.  3. 14.]\n",
    "# label_right [15. 12. 18. 15. 12. 18. 12. 16.  2.  0.]\n",
    "#attend01 [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
    "#omitted [0. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
    "\n",
    "# attend [11. 14.  2. 12.]\n",
    "# label_left [11. 14.  2. 6.]\n",
    "# label_right [15. 12. 12. 12.]\n",
    "#attend01 [0. 0.  0. 1.]\n",
    "\n",
    "#plotting just the first trials data\n",
    "trial_idx = 0\n",
    "plt.plot(left_input_LFP[trial_idx], label=\"Left Input LFP\")\n",
    "plt.plot(right_input_LFP[trial_idx], label=\"Right Input LFP\")\n",
    "plt.plot(attention_LFP[trial_idx], label=\"Attention Layer LFP\")\n",
    "plt.title(f\"LFP Data for Trial {trial_idx}\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"LFP\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#of non omitted trials\n",
    "#first left \n",
    "#second left\n",
    "#third left\n",
    "#fourth right \n",
    "\n",
    "#therefore expect greater wsmi on left for 1,2,3, and greater wsmi on right for 4\n",
    "\n",
    "left_input_triali = left_input_LFP[trial_idx]\n",
    "right_input_triali= right_input_LFP[trial_idx]\n",
    "attention_triali = attention_LFP[trial_idx]\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# Normalize each channel\n",
    "left_input_normalized = min_max_normalize(left_input_triali)\n",
    "right_input_normalized = min_max_normalize(right_input_triali)\n",
    "attention_normalized = min_max_normalize(attention_triali)\n",
    "\n",
    "plt.plot(left_input_normalized, label=\"Left Input LFP\")\n",
    "plt.plot(right_input_normalized, label=\"Right Input LFP\")\n",
    "plt.plot(attention_normalized, label=\"Attention Layer LFP\")\n",
    "plt.title(f\"Normalised LFP Data for Trial {trial_idx}\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"LFP\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Apply smoothing (e.g., Gaussian filter)\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "sigma = 5  # Standard deviation for Gaussian kernel\n",
    "left_input_smoothed = gaussian_filter1d(left_input_normalized, sigma)\n",
    "right_input_smoothed = gaussian_filter1d(right_input_normalized, sigma)\n",
    "attention_smoothed = gaussian_filter1d(attention_normalized, sigma)\n",
    "\n",
    "plt.plot(left_input_smoothed, label=\"Left Input LFP\")\n",
    "plt.plot(right_input_smoothed, label=\"Right Input LFP\")\n",
    "plt.plot(attention_smoothed, label=\"Attention Layer LFP\")\n",
    "plt.title(f\"Smoothed LFP Data for Trial {trial_idx}\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"LFP\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "raw_data_raw = np.stack([left_input_triali, right_input_triali, attention_triali])\n",
    "raw_data_normalised = np.stack([left_input_normalized, right_input_normalized, attention_normalized])\n",
    "raw_data_smoothed = np.stack([left_input_smoothed, right_input_smoothed, attention_smoothed])\n",
    "\n",
    "\n",
    "n_times = raw_data_raw.shape[1] ##=500\n",
    "print(\"n_samples\", n_times)\n",
    "\n",
    "dt = 0.002\n",
    "sfreq = 1 / dt\n",
    "ch_names = ['left_input', 'right_input', 'attention_layer']\n",
    "ch_types = ['eeg', 'eeg', 'eeg']\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "\n",
    "raw_data = mne.io.RawArray(raw_data_raw, info)\n",
    "raw_data_normalised = mne.io.RawArray(raw_data_normalised, info)\n",
    "raw_data_smoothed = mne.io.RawArray(raw_data_smoothed, info)\n",
    "\n",
    "\n",
    "events = np.array([\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "\n",
    "epochs_raw = mne.Epochs(raw_data, events, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "epochs_normalised = mne.Epochs(raw_data_normalised, events, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "epochs_smoothed = mne.Epochs(raw_data_smoothed, events, event_id={'Trial': 1}, tmin=0, tmax=(n_times - 1) / sfreq, baseline=None, preload=True)\n",
    "\n",
    "print(\"Raw data shape:\", raw_data.get_data().shape)\n",
    "print(\"Events array:\", events)\n",
    "print(\"Number of epochs:\", len(epochs_raw))\n",
    "\n",
    "\n",
    "kernel = 3\n",
    "taus = [8, 16, 32, 64]  # in ms\n",
    "#making wsmi results dictionary to store raw, normalised, and smoothed data\n",
    "wsmi_results = {'raw': {}, 'normalised': {}, 'smoothed': {}}\n",
    "\n",
    "for tau in taus:\n",
    "    tau_samples = int(tau / (1000 / sfreq))\n",
    "    print(f\"tau_samples for {tau}: {tau_samples}\")\n",
    "    \n",
    "    wsmi, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_raw, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "\n",
    "    wsmi_results['raw'][tau] = wsmi\n",
    "\n",
    "    wsmi, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_normalised, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "\n",
    "    wsmi_results['normalised'][tau] = wsmi\n",
    "\n",
    "    wsmi, _, _, _ = epochs_compute_wsmi(\n",
    "        epochs_smoothed, kernel=kernel, tau=tau_samples, backend='python', method_params={'bypass_csd': True}\n",
    "    )\n",
    "\n",
    "    wsmi_results['smoothed'][tau] = wsmi\n",
    "\n",
    "print(\"wsmi results raw\", wsmi_results['raw'][8])\n",
    "\n",
    "\n",
    "# Initialize lists to store wSMI values\n",
    "wsmi_left_attention_raw = []  # wSMI between left_input and attention_layer\n",
    "wsmi_right_attention_raw = []  # wSMI between right_input and attention_layer\n",
    "\n",
    "wsmi_left_attention_normalised = []  # wSMI between left_input and attention_layer\n",
    "wsmi_right_attention_normalised = []  # wSMI between right_input and attention_layer\n",
    "\n",
    "wsmi_left_attention_smoothed = []  # wSMI between left_input and attention_layer\n",
    "wsmi_right_attention_smoothed = []  # wSMI between right_input and attention_layer\n",
    "\n",
    "# Extract wSMI values for each tau\n",
    "for tau in taus:\n",
    "    wsmi_left_attention_raw.append(wsmi_results['raw'][tau][0, 2, 0])  # left_input vs attention_layer\n",
    "    wsmi_right_attention_raw.append(wsmi_results['raw'][tau][1, 2, 0])  # right_input vs attention_layer\n",
    "\n",
    "    wsmi_left_attention_normalised.append(wsmi_results['normalised'][tau][0, 2, 0])  # left_input vs attention_layer\n",
    "    wsmi_right_attention_normalised.append(wsmi_results['normalised'][tau][1, 2, 0])  # right_input vs attention_layer\n",
    "\n",
    "    wsmi_left_attention_smoothed.append(wsmi_results['smoothed'][tau][0, 2, 0])  # left_input vs attention_layer\n",
    "    wsmi_right_attention_smoothed.append(wsmi_results['smoothed'][tau][1, 2, 0])  # right_input vs attention_layer\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(3, 1, figsize=(6, 15))\n",
    "\n",
    "# Raw data plot\n",
    "axs[0].scatter(taus, wsmi_left_attention_raw, marker='o', label='Left Input vs Attention Layer', color='blue')\n",
    "axs[0].scatter(taus, wsmi_right_attention_raw, marker='o', label='Right Input vs Attention Layer', color='orange')\n",
    "axs[0].set_xlabel('Tau (ms)', fontsize=12)\n",
    "axs[0].set_ylabel('wSMI', fontsize=12)\n",
    "axs[0].set_title('Raw Data: wSMI vs Tau for Input vs Attention Layer', fontsize=14)\n",
    "axs[0].legend(fontsize=10)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Normalised data plot\n",
    "axs[1].scatter(taus, wsmi_left_attention_normalised, marker='o', label='Left Input vs Attention Layer', color='blue')\n",
    "axs[1].scatter(taus, wsmi_right_attention_normalised, marker='o', label='Right Input vs Attention Layer', color='orange')\n",
    "axs[1].set_xlabel('Tau (ms)', fontsize=12)\n",
    "axs[1].set_ylabel('wSMI', fontsize=12)\n",
    "axs[1].set_title('Normalised Data: wSMI vs Tau for Input vs Attention Layer', fontsize=14)\n",
    "axs[1].legend(fontsize=10)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Smoothed data plot\n",
    "axs[2].scatter(taus, wsmi_left_attention_smoothed, marker='o', label='Left Input vs Attention Layer', color='blue')\n",
    "axs[2].scatter(taus, wsmi_right_attention_smoothed, marker='o', label='Right Input vs Attention Layer', color='orange')\n",
    "axs[2].set_xlabel('Tau (ms)', fontsize=12)\n",
    "axs[2].set_ylabel('wSMI', fontsize=12)\n",
    "axs[2].set_title('Smoothed Data: wSMI vs Tau for Input vs Attention Layer', fontsize=14)\n",
    "axs[2].legend(fontsize=10)\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##person correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Compute correlation for left_input and attention_layer\n",
    "corr_left_attention, _ = pearsonr(left_input_triali, attention_triali)\n",
    "print(f\"Pearson correlation (Left Input vs. Attention Layer): {corr_left_attention}\")\n",
    "\n",
    "# Compute correlation for right_input and attention_layer\n",
    "corr_right_attention, _ = pearsonr(right_input_triali, attention_triali)\n",
    "print(f\"Pearson correlation (Right Input vs. Attention Layer): {corr_right_attention}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b312a-084e-42fe-bdad-bd5930e28b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "attleft_pearson_left = []\n",
    "attleft_pearson_right = []\n",
    "attright_pearson_left = []\n",
    "attright_pearson_right = []\n",
    "\n",
    "for i in range(len(left_indices)):\n",
    "    corr_left, _ = pearsonr(left_input_LFP_om_left[i], attention_LFP_om_left[i])\n",
    "    attleft_pearson_left.append(corr_left)\n",
    "    corr_right, _ = pearsonr(right_input_LFP_om_left[i], attention_LFP_om_left[i])\n",
    "    attleft_pearson_right.append(corr_right)\n",
    "\n",
    "for i in range(len(right_indices)):\n",
    "    ccrr_left, _ = pearsonr(left_input_LFP_om_right[i], attention_LFP_om_right[i])\n",
    "    attright_pearson_left.append(corr_left)\n",
    "    corr_right, _ = pearsonr(right_input_LFP_om_right[i], attention_LFP_om_right[i])\n",
    "    attright_pearson_right.append(corr_right)\n",
    "\n",
    "\n",
    "mean_corr_left_attleft = np.mean(attleft_pearson_left)\n",
    "mean_corr_right_attleft = np.mean(attleft_pearson_right)\n",
    "mean_corr_left_attright = np.mean(attright_pearson_left)\n",
    "mean_corr_right_attright = np.mean(attright_pearson_right)\n",
    "\n",
    "print(\"mean_corr_left_attleft\", mean_corr_left_attleft)\n",
    "print(\"mean_corr_right_attleft\", mean_corr_right_attleft)\n",
    "print(\"mean_corr_left_attright\", mean_corr_left_attright)\n",
    "print(\"mean_corr_right_attright\", mean_corr_right_attright)\n",
    "\n",
    "\n",
    "\n",
    "#with smoothing\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "sigma = 3  # Standard deviation for Gaussian kernel\n",
    "left_input_smoothed_att_left = gaussian_filter1d(left_input_LFP_om_left, sigma)\n",
    "left_input_smoothed_att_right = gaussian_filter1d(left_input_LFP_om_right, sigma)\n",
    "right_input_smoothed_att_left = gaussian_filter1d(right_input_LFP_om_left, sigma)\n",
    "right_input_smoothed_att_right = gaussian_filter1d(right_input_LFP_om_right, sigma)\n",
    "attention_smoothed_att_left = gaussian_filter1d(attention_LFP_om_left, sigma)\n",
    "attention_smoothed_att_right = gaussian_filter1d(attention_LFP_om_right, sigma)\n",
    "\n",
    "\n",
    "attleft_pearson_left = []\n",
    "attleft_pearson_right = []\n",
    "attright_pearson_left = []\n",
    "attright_pearson_right = []\n",
    "\n",
    "for i in range(len(left_indices)):\n",
    "    corr_left, _ = pearsonr(left_input_smoothed_att_left[i], attention_smoothed_att_left[i])\n",
    "    attleft_pearson_left.append(corr_left)\n",
    "    corr_right, _ = pearsonr(right_input_smoothed_att_left[i], attention_smoothed_att_left[i])\n",
    "    attleft_pearson_right.append(corr_right)\n",
    "\n",
    "for i in range(len(right_indices)):\n",
    "    corr_left, _ = pearsonr(left_input_smoothed_att_right[i], attention_smoothed_att_right[i])\n",
    "    attright_pearson_left.append(corr_left)\n",
    "    corr_right, _ = pearsonr(right_input_smoothed_att_right[i], attention_smoothed_att_right[i])\n",
    "    attright_pearson_right.append(corr_right)\n",
    "\n",
    "\n",
    "mean_corr_left_attleft = np.mean(attleft_pearson_left)\n",
    "mean_corr_right_attleft = np.mean(attleft_pearson_right)\n",
    "mean_corr_left_attright = np.mean(attright_pearson_left)\n",
    "mean_corr_right_attright = np.mean(attright_pearson_right)\n",
    "\n",
    "print(\"mean_corr_left_attleft\", mean_corr_left_attleft)\n",
    "print(\"mean_corr_right_attleft\", mean_corr_right_attleft)\n",
    "print(\"mean_corr_left_attright\", mean_corr_left_attright)\n",
    "print(\"mean_corr_right_attright\", mean_corr_right_attright)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
